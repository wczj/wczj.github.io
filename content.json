{"meta":{"title":"大炮的博客","subtitle":"","description":"","author":"王大炮","url":"http://wczj.github.io","root":"/"},"pages":[],"posts":[{"title":"算法学习","slug":"算法学习","date":"2022-02-19T10:33:18.000Z","updated":"2022-02-21T01:30:42.974Z","comments":true,"path":"2022/02/19/算法学习/","link":"","permalink":"http://wczj.github.io/2022/02/19/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"框架思维数据结构的存储方式只有两种：数组（顺序存储）和链表（链式存储）12数组和链表 是 结构基础散列表、栈、队列、堆、树、图等等各种数据结构 都是链表或者数组上的特殊操作， 是 上层建筑 数据结构的操作遍历 + 访问 (在不同的应用场景，尽可能高效地增删查改) 方式 1234线性的 for/while 为代表非线性的 递归为代表 算法和数据结构数据结构是工具，算法是通过合适的工具解决问题的方法12算法是利用数据结构进行显式利用算法是利用数据结构进行显式利用无论怎样利用数据结构，多么高大上的算法，其解法都逃不出第二点中相应的框架 总结123学会从框架上看问题，而不要纠结于细节问题即： 不要纠结 i 到底应该加到 n 还是加到 n - 1 而： 应该直接知道是使用什么数据结构进行如何 遍历和访问","categories":[{"name":"算法","slug":"算法","permalink":"http://wczj.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://wczj.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"趣谈网络协议","slug":"趣谈网络协议","date":"2022-02-16T11:53:19.000Z","updated":"2022-03-16T12:10:57.135Z","comments":true,"path":"2022/02/16/趣谈网络协议/","link":"","permalink":"http://wczj.github.io/2022/02/16/%E8%B6%A3%E8%B0%88%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"通信协议综述为什么要学习网络协议？12要打造互联网世界的通天塔，只教给一台机器做什么是不够的，你需要学会教给一大片机器做什么。这就需要网络协议通过网络协议，才能使一大片机器互相协作、共同完成一件事。 网络分层123为什么分层： 复杂的程序都分层，程序设计要求层层封装： 只要是在网络上跑的包，都是完整的。可以有下层没上层，绝对不可能有上层没下层。 ifconfig 命令12345678linux 查看ip地址： ifconfig， ip addr （工具： net-tools 和 iproute2 的故事）大部分的网卡都会有一个 IP 地址, 不是必需IP 地址是一个网卡在网络世界的通讯地址, 相当于门牌号， 不可冲突例： 10.100.122.2 就是一个 IP 地址。这个地址被点分隔为四个部分，每个部分 8 个 bit，所以 IP 地址总共是 32 位 因为不够用，于是就有了 IPv6，也就是上面输出结果里面 inet6 fe80::f816:3eff:fec7:7975/64。这个有 128 位 当初设计哪知道现在会有这么多计算机， 本来 32 位的 IP 地址就不够，还被分成了 5 类 12345对于 A、B、 C 类主要分两部分，前面一部分是网络号，后面一部分是主机号问题： C 类地址能包含的最大主机数量实在太少了，只有 254 个 而 B 类地址能包含的最大主机数量又太多了, 一般企业达不到6万多台机器， 闲着浪费 无类型域间选路（CIDR） 12345678910将 32 位的 IP 地址一分为二，前面是网络号，后面是主机号例： 10.100.122.2/24 这种地址表示形式，就是 CIDR。后面 24 的意思是，32 位中，前 24 位是网络号，后 8 位是主机号 伴随着 CIDR 存在的: 一个是广播地址，10.100.122.255。如果发送这个地址，所有 10.100.122 网络里面的机器都可以收到 另一个是子网掩码，255.255.255.0 将子网掩码和 IP 地址按位计算 AND，就可得到网络号: 如上面例子网络号就是： 10.100.122.0 公有 IP 地址和私有 IP 地址 1234567日常工作现在都是 CIDR, 几乎不用划分 A 类、B 类或者 C 类.私有IP： 是一个组织内部的， 公网之间可以重复公有IP： 是分配的的，需要买在ABC类IP地址中， 私有IP在上图中CIDR中常见的是 /24 的私有IP， 如: 192.168.0.x , 一般私有网络的出口地址，像路由器是 192.168.0.1， 而192.168.0.255是广播地址 D类组播地址 1使用这一类地址，属于某个组的机器都能收到。 ip addr 的继续分析12345678910111213root@test:~# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fec7:7975/64 scope link valid_lft forever preferred_lft forever 123456在 IP 地址的后面有个 scope 对于 eth0 这张网卡来讲，是 global，说明这张网卡是可以对外的，可以接收来自各个地方的包。 对于 lo 来讲，是 host，说明这张网卡仅仅可以供本机相互通信。 lo 全称是 loopback，又称环回接口，往往会被分配到 127.0.0.1 这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。 MAC 地址 在 IP 地址的上一行是 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff，这个被称为 MAC 地址，是一个网卡的物理地址，用十六进制，6 个 byte 表示 12345678910号称 全局唯一， 不会有两个网卡有相同的 MAC 地址，而且网卡自生产出来，就带着这个地址误解：MAC地址唯一，那整个互联网的通信，全部用 MAC 地址好了，只要知道了对方的 MAC 地址，就可以把信息传过去。正解： 一个网络包要从一个地方传到另一个地方，除了要有确定的地址，还需要有定位功能。 而有门牌号码属性的 IP 地址，才是有远程定位功能的MAC 地址更像是身份证，是一个唯一的标识MAC 地址是有一定定位功能的，只不过范围非常有限， 局限在一个子网里面。 例： 从 192.168.0.2/24 访问 192.168.0.3/24 是可以用 MAC 地址的。 网络设备的状态标识 &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; 是干什么的？这个叫做 net_device flags，网络设备的状态标识。 1234UP 表示网卡处于启动的状态；BROADCAST 表示这个网卡有广播地址，可以发送广播包；MULTICAST 表示网卡可以发送多播包；LOWER_UP 表示 L1 是启动的，也即网线插着呢。 MTU1500 MTU1500 是指什么意思呢？是哪一层的概念呢？最大传输单元 MTU 为 1500，这是以太网的默认值。 123MTU 是二层 MAC 层的概念。MAC 层有 MAC 的头，以太网规定正文部分不允许超过 1500 个字节。正文里面有 IP 的头、TCP 的头、HTTP 的头。如果放不下，就需要分片来传输。 qdisc 排队规则 qdisc pfifo_fast 是什么意思呢？qdisc 全称是 queueing discipline，中文叫排队规则。 12345678内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的 qdisc（排队规则）把数据包加入队列队列类型： pfifo : 最简单， 先进先出 pfifo_fast : 它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。 三个波段（band）的优先级也不相同。band 0 最高，band 2 最低。 如果 band 0 里面有数据包，系统就不会处理 band 1 里面的数据包 数据包是按照服务类型（Type of Service，TOS）被分配到三个波段（band）里面的。TOS 是 IP 头里面的一个字段，代表了当前的包是高优先级的，还是低优先级的 总结 IP 是地址，有定位功能；MAC 是身份证，无定位功能； CIDR 可以用来判断是不是本地人； IP 分公有的 IP 和私有的 IP DHCP 和 PXE ： IP怎么来？ 怎么没？如何配置IP地址使用 net-tools 12$ sudo ifconfig eth1 10.0.0.1/24$ sudo ifconfig eth1 up 使用 iproute2： 12$ sudo ip addr add 10.0.0.1/24 dev eth1$ sudo ip link set up eth1 思考： 192.168.1.6 就在你这台机器的旁边，甚至是在同一个交换机上，而你把机器的地址设为了 16.158.23.6。 为什么ping不通？ 123456789原则： 只要是在网络上跑的包，都是完整的，可以有下层没上层，绝对不可能有上层没下层。逻辑分析： 它有自己的源 IP 地址 16.158.23.6，也有目标 IP 地址 192.168.1.6，但是包发不出去，这是因为 MAC 层还没填 Linux 首先会判断，要去的这个地址和我是一个网段的吗，或者和我的一个网卡是同一网段的吗？ 只有是一个网段的，它才会发送 ARP 请求，获取 MAC 地址 如果不是， 这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。 而linux中网关的配置， 网关要和当前的网络至少一个网卡是同一个网段的 1不同系统的配置文件格式不同，但是无非就是 CIDR、子网掩码、广播地址和网关地址。 动态主机配置协议（DHCP）（Dynamic Host Configuration Protocol）123他只需要配置一段共享的 IP 地址。每一台新接入的机器都通过 DHCP 协议，来这个共享的 IP 地址里申请，然后自动配置好就可以了。等人走了，或者用完了，还回去，这样其他的机器也能用。 DHCP 工作方式 新机器加入网络 12345678910111213141516第一步. client进行 DHCP Discover （ 广播 Boot request，我的 MAC 地址是这个，我还没有 IP) 新机器使用 IP 地址 0.0.0.0 发送了一个广播包，目的 IP 地址为 255.255.255.255。广播包封装了 UDP，UDP 封装了 BOOTP。 （其实 DHCP 是 BOOTP 的增强版） 第二步. DHCP server 进行 DHCP offer MAC地址唯一，新MAC地址来了，分配IP地址，并为他保留 。 仍然使用广播地址作为目的地址 第三步，client 进行 DHCP request 新机器得到 offer， 如果有多个DHCP server， 甚至得到多个offer 一般选择最新到达的offer，然后向网络发送一个 DHCP Request 广播数据包，包中包含客户端的 MAC 地址、接受的租约中的 IP 地址、提供此租约的 DHCP 服务器地址等 告诉所有 DHCP Server 它将接受哪一台服务器提供的 IP 地址，告诉其他 DHCP 服务器，谢谢你们的接纳，并请求撤销它们提供的 IP 地址，以便提供给下一个 IP 租用请求者 由于还没有得到 DHCP Server 的最后确认，客户端仍然使用 0.0.0.0 为源 IP 地址、255.255.255.255 为目标地址进行广播第四步， server 进行 DHCP ACK 当 DHCP Server 接收到客户机的 DHCP request 之后， 会广播返回给客户机一个 DHCP ACK 消息包，表明已经接受客户机的选择，并将这一 IP 地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。 广播也是告诉其他server， 该client在我这个server租了IP IP地址的收回和续租 123续租： 客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的 DHCP Server 发送 DHCP request 消息包 客户机接收到该服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新的 TCP/IP 参数，更新自己的配置 自动安装操作系统 预启动执行环境（PXE） 场景： 数据中心里面的管理员可能一下子就拿到几百台空的机器，一个个安装操作系统，会累死的 1234567891011办法： 安装的操作系统放在一个服务器上，让客户端去下载。 问题： 没有操作系统，客户端放哪里？ 解决： 操作系统的启动过程: 首先启动BIOS, 读取硬盘的 MBR 启动扇区，将 GRUB 启动起来；然后将权力交给 GRUB，GRUB 加载内核、加载作为根文件系统的 initramfs 文件；然后将权力交给内核；最后内核启动，初始化整个操作系统 在整个过程中, 只能放在BIOS启动后,因为没安装系统之前，连启动扇区都没有 这个过程叫做预启动执行环境（Pre-boot Execution Environment），简称 PXE。 PXE 协议分为客户端和服务器端，由于还没有操作系统，只能先把客户端放在 BIOS 里面。当计算机启动时，BIOS 把 PXE 客户端调入内存里面，就可以连接到服务端做一些操作了 首先 PXE 的客户端启动起来，发送一个 DHCP 的请求，让 DHCP Server 给它分配一个地址。PXE 客户端有了自己的地址 怎么知道 PXE 服务器在哪里呢？ 在DHCP server 中配置 next-server，指向 PXE 服务器的地址，配置初始启动文件位置 filename 然后TFTP，从 PXE服务器下载 PXE 工作过程 底层网络知识详解： 从二层到三层从 物理层 到 MAC层 : 学校宿舍几台电脑之间联网物理层123456789使用路由器联网，是在第三层 物理层联网: 两台电脑： 在物理层联网， 一根网线连接两台电脑的网口 但普通的网线不行，水晶头要做交叉线，就是所谓的 1－3、2－6 交叉接法。 （水晶头的第 1、2 和第 3、6 脚，它们分别起着收、发信号的作用。将一端的 1 号和 3 号线、2 号和 6 号线互换一下位置，就能够在物理层实现一端发送的信号，另一端能收到） 然后配置两台电脑的 IP 地址、子网掩码和默认网关， 配置成同一个网络， 例：可以一个是 192.168.0.1/24，另一个是 192.168.0.2/24 三台电脑： 使用集线器Hub，和交换机不同，没有大脑，完全在物理层工作，将收到的字节复制到其他接口 数据链路层 （第二层） 问题： 多台电脑使用Hub进行物理层联网后： 广播，一台电脑发出的包所有电脑都能收到 这个包是发给谁的？谁应该接收？ 大家都在发，会不会产生混乱？有没有谁先发、谁后发的规则？ 如果发送的时候出现了错误，怎么办？ 在第二层， 数据链路层， 也即 MAC层解决 MAC 的全称是 Medium Access Control，即媒体访问控制。 就是控制在往媒体上发数据的时候，谁先发、谁后发, 防止发生混乱。这解决的是第二个问题。这个问题中的规则，学名叫多路访问 解决第二个问题: 谁先发，谁后发？ 123方式一： 分多个车道。每个车一个车道，你走你的，我走我的。 （ 信道划分 ）方式二： 今天单号出行，明天双号出行，轮着来 （ 轮流协议 ）方式三： 不管三七二十一，有事儿先出门，发现特堵，就回去，错过高峰再出 （ 随机接入协议 ） （ 以太网就是这种 ） 解决第一个问题: 发给谁？ 谁接收？ / 解决第三个问题： 发送出错怎么办？ 这里用到一个物理地址，叫作链路层地址。但是因为第二层主要解决媒体接入控制的问题，所以它常被称为 MAC 地址 第二层的网络包格式 123456目标的 MAC 地址源的 MAC 地址类型： IP 数据包，然后 IP 里面包含 TCP、UDP，以及 HTTP 等，这都是里层封装的事情 ARP 数据包CRC： 循环冗余检测 123问题： 一个广播的网络里面接入了 N 台机器，我怎么知道每个 MAC 地址是谁呢？ARP 协议，也就是已知 IP 地址，求 MAC 地址的协议发送一个广播包，谁是这个 IP 谁来回答。 为了避免每次都用 ARP 请求，机器本地也会进行 ARP 缓存， 机器会不断地上线下线，IP 也可能会变，所有缓存需要过期 局域网 Hub 是广播的，不管某个接口是否需要，所有的 Bit 都会被发送出去，然后让主机来判断是不是需要 机器少没问题，多了冲突概率就高， 而且把不需要的包转发过去，纯属浪费 换智能的： 二层设备 - 交换机 每个口都只连接一台电脑，这台电脑又不怎么换 IP 和 MAC 地址，只要记住这台电脑的 MAC 地址，如果目标 MAC 地址不是这台电脑的，这个口就不用转发了。 123456例： MAC1 电脑将一个包发送给 MAC2 电脑 一开始交换机也不知道 MAC2 的电脑在哪个口，所以没办法，它只能将包转发给除了来的那个口之外的其他所有的口 但是，这个时候，交换机会记住这个口 MAC1 的， 以后有包的目的地址是 MAC1 的，直接发送到这个口就可以了。 交换机学习的结果称为 转发表： 有过期时间 ( 因为地址会变 ） 小结123MAC 层是用来解决多路访问的堵车问题的ARP 是通过吼的方式来寻找目标 MAC 地址的，吼完之后记住一段时间，这个叫作缓存；交换机是有 MAC 地址学习能力的，学完了它就知道谁在哪儿了，不用广播了 交换机与VLAN：办公室太复杂，我要回学校拓扑结构12办公室，整个公司多个楼层，几百个网口。 一台交换机肯定不够了，需要多台交换机， 然后交换机连起来， 就形成了稍微复杂的拓扑结构 环路问题 当两个交换机将两个局域网同时连接起来的时候 12刚开始机器 1 访问机器 2， 广播 ARP 包这个包会在环路里转来转去， 多个机器都发广播包，广播包越来越多。 按上面共享道路的算法，也就是路会越来越堵，最后谁也别想走 如何破坏环路？ STP协议 1234数据结构中，有一个方法叫做最小生成树。有环的我们常称为图。将图中的环破了，就生成了树在计算机网络中，生成树的算法叫作 STP，全称 Spanning Tree Protocol理解： 华山论剑，最终决出五岳盟主 STP中的概念 123456Root Bridge: 根交换机, 树的老大Designated Bridges: 指定交换机, 理解： 我拜谁做大哥，指定我的小弟也拜这个为大哥 Bridge Protocol Data Units （BPDU）: 网桥协议数据单元, 理解为 “相互比较实力”的协议 Priority Vector： 优先级向量。 可以比喻为实力 （值越小越牛） [Root Bridge ID, Root Path Cost, Bridge ID, and Port ID] 实力比较： 先看Root Bridge ID （老大的实力）， 再比 Root Path Cost（跟老大的关系远近） ， 最后 Bridge ID（自己的实力） STP 工作过程 123451. 一开始，江湖纷争，异常混乱。大家都觉得自己是掌门，谁也不服谁。于是，所有的交换机都认为自己是掌门2. 但每个网桥都会被分配一个ID， 网络管理员知道哪些交换机贵，哪些交换机好，就会给它们分配高的优先级， 即有些交换机生下来实力就强3. 开始互相发送 BPDU 来比功夫4. 赢的接着当掌门，输的做小弟。 掌门继续发BPDU， 小弟就没机会了。 只有在收到掌门发的 BPDU 的时候，转发一下，表示服从命令。5. 出现了很多小的门派，然后小的门派，接着合并， 最后生成一棵树，武林一统 广播问题， 安全问题 12广播问题（性能）： 机器多了，交换机也多了，就算交换机比 Hub 智能一些，但是还是难免有广播的问题。 广播一大堆，性能就下来了安全问题： 由于在同一个广播域里面，很多包都会在一个局域网里面飘啊飘，碰到了一个会抓包的程序员，就能抓到这些包，如果没有加密，就能看到这些敏感信息了 办法一、 物理隔离 123每个部门有单独的交换机，配置单独的子网，这样部门之间的沟通就需要路由器了问题： 每个部门有单独的交换机，口多了浪费，少了又不够用。 办法二、 虚拟隔离 （ VLAN， 虚拟局域网 ） 使用 VLAN，一个交换机上会连属于多个局域网的机器，那交换机怎么区分哪个机器属于哪个局域网呢？ 在原来的二层 MAC的头上加一个 TAG，里面有一个 VLAN ID，一共 12 位 123456只要买的交换机是支持 VLAN的，当这个交换机把二层的头取下来的时候，就能够识别这个 VLAN ID。可以设置交换机每个口所属的 VLAN 这样只有相同 VLAN 的包，才会互相转发，不同 VLAN 的包，是看不到的。这样广播问题和安全问题就都能够解决了 交换机之间怎么连接呢? 设置为 Trunk 口， 转发属于任何 VLAN 的口 ICMP与ping：投石问路的侦察兵 ICMP 全称 Internet Control Message Protocol，就是互联网控制报文协议。 ICMP 报文是封装在 IP 包里面的 ICMP 的格式 12网络包在复杂网络环境中传输遇到问题的时候，不能“死个不明不白”，要传出消息来，报告情况ICMP 常用类型： 主动请求为 8，主动请求的应答为 0 查询报文类型 12345678主动查询网络状况ping 就是查询报文，是一种主动请求，并且获得主动应答的 ICMP 协议。在后面增加了自己的格式对 ping 的主动请求，进行网络抓包，称为 ICMP ECHO REQUEST。同理主动请求的回复，称为ICMP ECHO REPLY多了两个字段： 标识符： 理解： 两队侦查兵，一队是侦查战况的，一队是去查找水源 序号： 对派出去的包编号，回来多网络好，回来少网络差在选项数据中： ping 还会存放发送请求的时间值，来计算往返时间，说明路程的长短 ping：查询报文类型的使用 1在ping中间的设备或者路由， 使用 tcpdump -i eth0 icmp 可以查看包有没有到达这个点 差错报文类型 12345678910异常情况发起的，来报告发生了不好的事情例： 终点不可达为 3 具体原因在代码中： 网络不可达代码为 0，主机不可达代码为 1，协议不可达代码为 2，端口不可达代码为 3，需要进行分片但设置了不分片位代码为 4 源抑制为 4 让源站放慢发送速度 超时为 11 超过网络包的生存时间还是没到 重定向为 5 让下次发给另一个路由器 （更优路径） Traceroute：差错报文类型的使用 12345678910111213可故意设置一些能够产生错误的场景Traceroute 的第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器 设置为1， 即到达第一个路由或关卡就失败， 设置为2，3，最终获得中间所有路由 （公网路由都设置不会回这个ICMP，所有拿不到公网的）如何查看UDP报文有没有到达目的主机？ 发送UDP 数据报给目的主机，选择一个不可能的UDP 端口号（大于 30000） 如果到达目的主机返回端口不可达， 没到返回超时Traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU 首先是发送分组，并设置“不分片”标志 发送的第一个分组的长度正好与出口 MTU 相等 如果中间遇到窄的关口会被卡住，会发送 ICMP 网络差错包，类型为“需要进行分片但设置了不分片位”。每次收到 ICMP“不能分片”差错时就减小分组的长度，直到到达目标主机。 出网关123456789上网： 在进行网卡配置的时候，除了 IP 地址，还需要配置一个Gateway网关在任何一台机器上，当要访问另一个 IP 地址的时候，都会先判断目标 IP 地址，和当前机器的 IP 地址，是否在同一个网段? 判断网段是否一样： 需要 CIDR 和子网掩码同一网段： 直接将源/目标地址放入 IP 头中，然后通过 ARP 获得 MAC 地址，将源/目的 MAC 放入 MAC 头中，发出去就可以了不同网段： 发往默认网关。Gateway 的地址一定是和源 IP 地址是一个网段的网关往往是一个路由器，是一个三层转发的设备: 就是把 MAC 头和 IP 头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备 静态路由 123456789101112131415161718路由器： 多个网卡，连着多个局域网，每个网卡跟一个局域网网段相同， 一个数据包从一个口进来从哪个口出去，根据路由算法路由分为： 静态路由， 动态路由静态路由： 就是在路由器上配置 一条条匹配规则， 从哪个口出去是什么地址。 ``` - IP 头和 MAC 头哪些变、哪些不变 ?两种类型网关```textMAC 地址是一个局域网内才有效的地址MAC 地址只要过网关，就必定会改变，因为已经换了局域网主要看IP是否变?IP地址不变的网关： 转发网关而IP地址变的网关： NAT网关 转发网关 1局域网之间的网段不会冲突， 即源/目标IP 不可能重复， 所以只需要 MAC地址修改进行转发 NAT网关 (Network Address Translation) 12345678局域网之间，各定各的网段， IP冲突。 如上两天服务器的IP地址是相同的解决： 既然局域网之间没有商量过，各管各的。 那到国际上，也即中间的局域网里面，就需要使用另外的地址，就想出国，不用身份证，用护照 例： 服务器 A 的国际身份是 192.168.56.1 , 服务器 B 的国际身份是 192.168.56.2 在网关上记录下身份， 出国就转换为国际身份，入国就转换为国内身份, 身份转换就是 NAT网关进行的IP转换 路由协议 配置路由 12345678路由表: 当一个入口的网络包送到路由器时，它会根据一个本地的转发信息库，来决定如何正确地转发流量。 路由规则 （至少包含三个信息）： 1. 目的网络：这个包想去哪儿？ 2. 出口设备：将包从哪个口扔出去？ 3. 下一跳网关：下一个路由器的地址。 核心思想： 根据目的 IP 地址来配置路由 配置策略路由 在真实的复杂的网络环境中， 根据多个参数来配置路由 123可以配置多个路由表可以根据源 IP 地址、入口设备、TOS 等选择路由表，然后在路由表中查找路由这样可以使得来自不同来源的包走不同的路由 动态路由算法12345678使用动态路由路由器，可以根据路由协议算法生成动态路由表，随网络运行状况的变化而变化。无论是一个国家内部，还是国家之间，我们都可以将复杂的路径，抽象为一种叫作图的数据结构最终肯定是路越少越好，道路越短越好，因而这就转化成为如何在途中找到最短路径的问题。最短路径常用的有两种方法: Bellman-Ford 算法 Dijkstra 算法 距离矢量路由（ distance vector routing ) , 基于 Bellman-Ford 算法 123456789基本思路： 每个路由器保存一个路由表，包含多行，每行对应网络中的一个路由器，包含两部分信息，一个是要到目标路由器，从那条线出去，另一个是到目标路由器的距离。 每个路由器知道全局信息： 每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。 问题： 1. 好消息传得快，坏消息传得慢。 新路由器上线能很快通知邻居然后广播出去。 但路由挂了不会广播消息，当每个路由器发现原来的道路到不了这个路由器的时候，感觉不到它已经挂了，而是试图通过其他的路径访问，直到试过了所有的路径，才发现这个路由器是真的挂了。 2. 每次发送的时候，要发送整个全局路由表 链路状态路由算法（link state routing），基于 Dijkstra 算法 1234567基本思路： 路由器启动，向邻居，发送一个 echo，要求马上返回，除以二就是距离。 然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器 然后每个路由器都能在自己本地构建一个完整的图, 然后针对这个图使用 Dijkstra 算法，找到两点之间的最短路径 链路状态路由协议只广播更新的或改变的网络拓扑而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛 路由协议 基于链路状态路由算法的 OSPF 路由协议 主要用在数据中心内部，用于路由决策 , 因而也称为内部网关协议（Interior Gateway Protocol，简称 IGP）。 12OSPF（Open Shortest Path First，开放式最短路径优先）多个最短的路径: 等价路由 （ 可进行负载均衡 ） 基于距离矢量路由算法的 BGP 路由协议 外网路由协议（Border Gateway Protocol，简称 BGP） 使用 路径矢量路由协议（path-vector protocol）， 是距离矢量路由协议的升级版 1外网除了路径远近外，还有路过的不同数据中心不同policy的问题， 哪些IP能通过/不能通过。 AS ( Autonomous System ) 自治系统 123Stub AS：对外只有一个连接。这类 AS 不会传输其他 AS 的包 （个人，小公司的网络）Multihomed AS：可能有多个连接连到其他的 AS，但是大多拒绝帮其他的 AS 传输包 （ 大公司网络 ） Transit AS：有多个连接连到其他的 AS，并且可以帮助其他的 AS 传输包 ( 主干网络 ） 最重要的传输层 主要： TCP 、 UDP 123456789101112131415区别： TCP 是面向连接的，UDP 是面向无连接的所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。TCP: 提供可靠交付。 无差错、不丢失、不重复、并且按序到达。 面向字节流。 IP包是一个个包发的，变成流是TCP维护的 拥塞控制， 意识到自己包丢了或网络慢了，会调整自己的发送速度 是一个有状态服务UDP： 不保证不丢失，不保证按顺序到达。 基于数据包，一个个收发 无状态服务 MAC 层定义了本地局域网的传输行为，IP 层定义了整个网络端到端的传输行为，这两层基本定义了这样的基因： 网络传输是以包为单位的，二层叫帧，网络层叫包，传输层叫段 UDP 包头: IP包送到某个地址， UDP则是送到某个端口 UDP 三个特点 1231. 沟通简单： 相信网络通路默认就是很容易送达的2. 轻信他人： 不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，他也可以传给任何人数据3. 做事不变： 不管网络情况，该怎么发就怎么发 使用场景 12345671. 需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用 DHCP（内网获取IP地址，失败可重新来）， TFTP 2. 不需要一对一沟通，建立连接，而是可以广播的应用3. 需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候 要有自己的连接策略，应用层实现 例子 12345678910111213141516171. 网页或者 APP 的访问 一般基于TCP的HTTP协议， QUIC（全称 Quick UDP Internet Connections，快速 UDP 互联网连接）是 Google 提出的一种基于 UDP 改进的通信协议，其目的是降低网络通信的延迟，提供更好的用户互动体验。 在应用层上，会自己实现快速连接建立、减少重传时延，自适应拥塞控制2. 流媒体的协议 直播协议多使用基于 TCP 的 RTMP 但隔几个帧丢一个，其实看视频的人不会感知。因而，很多直播应用，都基于 UDP 实现了自己的视频传输协议。 3. 实时游戏 实时性比较高，采用自定义的可靠 UDP 协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响 4. IOT 物联网 资源少，维护 TCP 协议代价太大。 对实时性要求也很高。 5. 移动通信领域 移动流量上网的数据面对的协议 GTP-U 是基于 UDP 的 TCP 123456789101112端口： 需要知道发给那个应用，应用监听端口序号： 为了解决乱序确认序号： 发出去的包应该有确认，没收到就重发。 不丢包状态位： （TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更） SYN 是发起一个连接 ACK 是回复 RST 是重新连接 FIN 是结束连接窗口大小: 流量控制，通信双方各声明一个窗口，标识自己当前能够的处理能力，别发送的太快，也别发的太慢 TCP重点关注问题 12345顺序问题丢包问题连接维护流量控制拥塞控制 TCP 三次握手 保证双方的消息有去有回就可以了 123456三次握手处理建立连接， 还沟通 TCP包的序号问题， 从哪个序号开始发送每个连接都要有不同的序号。 这个序号的起始序号是随着时间变化的，可以看成一个 32 位的计数器，每 4 微秒加一， 如果计算一下，如果到重复，需要 4 个多小时，那个绕路的包早就死翘翘了， 因为我们都知道 IP 包头里面有个 TTL，也即生存时间 TCP 四次挥手 1 连接建立和断开的TCP状态机 TCP 如何实现靠谱？ 顺序发送保证应答 123为了保证顺序性，每一个包都有一个 ID在建立连接的时候，会商定起始的 ID 是什么，然后按照 ID 一个个发送为了保证不丢包，对于发送的包都要进行应答，不应答每个包，而是应答某个之前的 ID，表示都收到了，这种模式称为累计确认或者累计应答（cumulative acknowledgment） 发送端和接收端分别都有缓存来保存这些记录（所有发送和接收的包） 12345678910发送端, 按照包的 ID 一个个排列, 分四部分1. 发送了并且已经确认2. 发送但尚未确认3. 未发送但等待发送4. 未发送且暂时不会发送 流量控制: 接收端会给发送端报一个窗口的大小，叫 Advertised window 窗口的大小 等于 上面的第二，三部分。 而第四部分就是超过窗口不能发送的 1234567891011接收端， 三部分1. 接受并且确认过的2. 还没接收，但是马上就能接收的。 即 能够接受的最大工作量3. 还没接收，也没法接收的。 即 超过工作量的第一，二 部分加起来是 接收端能接收的最大数量第一部分是 已接收确认并确认，但未被应用使用的第二部分就是 能接收的最大工作量, 即发送给接收端的 Advertised window在第二部分中， 收到的包可能不是按顺序的，所以只有和第一部分连续的包可以进行马上回复，如果来的包不连续需要等待 顺序问题与丢包问题 12345678910确认重发机制 超时重传： 每个发送但未ACK的包，有一个定时器，超时就进行重新尝试 超时时间的确定： 必须大于往返时间 RTT自适应重传算法（Adaptive Retransmission Algorithm）： 估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断地变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间 TCP的策略： 超时 间隔加倍。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送 流量控制问题 12345接收方在对于包的确认中，同时会携带一个窗口的大小极端情况，接收端的应用一直不读取缓存中的数据，则随着确认的包越来越多，窗口越来越小，直到为 0发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。 而发送方不是空出一字节就马上调整的， 是达到一定大小才更新窗口 拥塞控制问题 123456789也是通过窗口的大小来控制的： 前面的滑动窗口 rwnd 是怕发送方把接收方缓存塞满 而拥塞窗口 cwnd，是怕把网络塞满公式 LastByteSent - LastByteAcked &lt;= min &#123;cwnd, rwnd&#125; ，是拥塞窗口和滑动窗口共同控制发送的速度。 通道的容量 = 带宽 × 往返延迟。设置发送窗口，使得 发送但未确认的包 为通道的容量，就能够撑满整个管道TCP 的拥塞控制主要来避免两种现象，包丢失和超时重传 cwnd 拥塞窗口的慢启动 123456一条 TCP 连接开始： cwnd设置为1， 一次只能发送一个， 然后收到每个确认加1， 即下次2个，然后2个确认变4，然后变8，指数增长 指数增长到 ssthresh 的值， 就慢下来，每个确认增加 1/cwnd，即每次所有确认收到后加一，变成线性增长 线性增长最终出现拥塞即出现丢包现象，降低速度。 一种是： 将 sshresh 设为 cwnd/2，将 cwnd 设为 1，重新开始慢启动。 太激进，高速传输一下停止，容易网络卡顿 二种是： 将cwnd 减半为 cwnd/2，然后 sshthresh = cwnd。 还在比较高的值，呈线性增长 123456TCP 拥塞控制的问题1.丢包并不代表着通道满了，也可能是管子本来就漏水。 如公网网络状况不好，这个时候就认为拥塞了，速度降低是不对的2. TCP 的拥塞控制要等到将中间设备的缓存都填充满了，才发生丢包，从而速度降低。 TCP 只要填满管道就可以了，不应该接着填为了优化这两个问题，后来有了 TCP BBR 拥塞算法 基于 TCP 和 UDP 协议的 Socket 编程12345分客户端和服务端, 理解为一根网线，一头插在客户端，一头插在服务端，然后进行通信。 在通信之前，双方都要建立一个 Socket。参数设置： 指定是 IPv4 还是 IPv6，分别对应设置为 AF_INET 和 AF_INET6 指定是 TCP 还是 UDP， 分别对应 基于数据流SOCK_STREAM 和 基于数据报SOCK_DGRAM 基于 TCP 协议的 Socket 程序函数调用过程123456789101112131415161718服务端socket： 先 bind 进行绑定 IP地址和端口 listen 进行监听 内核维护两个队列： 1. 已经建立了连接的队列 ， 已完成三次握手， 处于 established 状态 2. 还没有完全建立连接的队列， 处于三次握手中， 处于 syn_rcvd 的状态 调用 accept 函数，拿出一个已经完成的连接进行处理 客户端socket： 在服务端进入listen状态后， 可以使用 connect 发起连接（指明连接IP和端口），进行三次握手 内核给客户端分配一个临时端口 握手成功，服务端的 accept 就会返回另一个 Socket注意： 监听的 Socket 和真正用来传数据的 Socket 是两个: 监听socket， 已连接socket 两端连接建立后： 双方都通过 read， write 进行读写数据， 像文件流读写一样 123456789101112Socket 在 Linux 中就是以文件的形式存在的 存在文件描述符。写入和读出，都是通过文件描述符每一个进程都有一个数据结构 task_struct，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。 文件描述符是一个整数，是这个数组的下标。 内容是指针，指向文件地址一个文件，就会有一个 inode 只不过 Socket 对应的 inode 不像真正的文件系统一样，保存在硬盘上的，而是在内存中的。 在这个 inode 中，指向了 Socket 在内核中的 Socket 结构socket 结构： 主要是两个队列 - 发送队列 和 接收队列 在这两个队列里面保存的是一个缓存 sk_buff。这个缓存里面能够看到完整的包的结构。 用于收发包 基于 UDP 协议的 Socket 程序函数调用过程12345UDP 没有连接，不需要三次握手，也就不需要调用 listen 和 connect 但是，UDP 的交互仍然需要 IP 和端口号，因而也需要 bind。UDP 没有维护连接状态，因而不需要每对连接建立一组 Socket，而是只要有一个 Socket，就能够和多个客户端通信。也正因为没有连接状态，每次通信的时候，都调用 sendto 和 recvfrom，都可以传入 IP 地址和端口。 服务器如何接更多的项目？ 最大连接数 一个四元组 标识 一个 TCP 连接: {本机IP, 本机端口, 对端IP, 对端端口} 123456对服务端来说： 最大 TCP 连接数 = 客户端 IP 数×客户端端口数 对 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数，约为 2 的 48 次方。实际限制： 1. 文件描述符限制： Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目； 2. 内存：每个 TCP 连接都要占用一定内存 在资源有限的情况下，如何降低每个连接消耗的资源数目。达到更多的连接数 123456789101112131415161718192021222324252627282930313233343536373839401. 多进程方式 (将项目外包给其他公司) 一旦建立了一个连接，就会有一个已连接 Socket，这时候你可以创建一个子进程，然后将基于已连接 Socket 的交互交给这个新的子进程来做 Linux 下，创建子进程使用 fork 函数。这是在父进程的基础上完全拷贝一个子进程。 在 Linux 内核中，会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到了哪一行程序的进程。 显然，复制的时候在调用 fork，复制完毕之后，父进程和子进程都会记录当前刚刚执行完 fork。这两个进程刚复制完的时候，几乎一模一样，只是根据 fork 的返回值来区分到底是父进程，还是子进程。如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。 复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的, 子进程直接就可以通过这个已连接 Socket 和客户端进行互通 最后子进程通信完成，父进程根据子进程ID查看是否退出子进程 2. 多线程方式（将项目转包给独立的项目组） 在 Linux 下，通过 pthread_create 创建一个线程，也是调用 do_fork 但很多资源，例如文件描述符列表、进程空间，是共享的，只不过多了一个引用而已。 新的线程也可以通过已连接 Socket 处理请求，从而达到并发处理的目的上面两种问题： 每次新到来一个 TCP 连接，就需要分配一个进程或者线程 一台机器无法创建很多进程或者线程。有个 C10K 问题3. IO 多路复用，一个线程维护多个 Socket （一个项目组支撑多个项目） 某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中 然后调用 select 函数来监听这个文件描述符集合是否有变化。 一旦有变化，就会依次查看每个文件描述符。 那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作， 然后再调用 select，接着盯着下一轮的变化。 4. IO 多路复用，从“派人盯着”到“有事通知” (一个项目组支撑多个项目) 上面第三种方法，select查询集合的问题： Socket文件描述符集合中有发生变化时，采用轮询的方法需要将整个集合过一遍，这样效率太低，影响线程能处理的最大socket数量 因而使用 select，能够同时盯的项目数量由 FD_SETSIZE 限制 改进： 改成事件通知的方式， 能完成这件事情的函数叫 epoll，它在内核中的实现不是通过轮询的方式，而是通过注册 callback 函数的方式，当某个文件描述符发送变化的时候，就会主动通知 进程打开了多个 socket 文件描述符， epoll_create 创建一个 epoll 对象，也是个文件，内容是红黑树， 保存这个 epoll 监听的所有 Socket。 当 epoll_ctl 添加一个 Socket 的时候，其实是加入这个红黑树，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的 Socket 的事件列表中。当一个 Socket 来了一个事件的时候，可以从这个列表中得到 epoll 对象，并调用 call back 通知它。 使用这种方式， 能够同时监听的 Socket 的数目就非常的多了。上限就为系统定义的、进程打开的最大文件描述符个数 epoll 被称为解决 C10K 问题的利器。 应用层HTTP数据中心DNS协议， 网络世界的地址簿 DNS 服务器 123456DNS 服务器，一定要设置成高可用、高并发和分布式的分为三层： 根 DNS 服务器： 返回顶级域 DNS 服务器的 IP 地址 顶级域 DNS 服务器: 返回权威 DNS 服务器的 IP 地址 权威 DNS 服务器 ：返回相应主机的 IP 地址 DNS 解析流程 12341. 先访问 本地域名服务器 （如移动电信等网络服务商的机房）2. 本地域名服务器 找到直接返回IP， 没找到则访问 根域名服务器（全球共 13 套。它不直接用于域名解析，返回顶级域名服务器地址）3. 本地域名服务器 访问 顶级域名服务器（ 也不直接域名解析，返回权威域名服务器的地址 ）4. 本地域名服务器 访问 权威域名服务器 （ 进行域名解析查询到对应的IP返回 ） DNS 负载均衡 内部负载均衡 123多个应用访问一个数据库： 如果配置IP，IP换了就需要所有应用修改配置， 如果配置了域名，只需要将域名映射为新的IPA应用访问应用B， 如果应用B撑不住了，可以集群部署，域名配置对应多个应用B的IP，配置域名解析的策略，进行负载均衡 全局负载均衡 12345基于 DNS 的全局负载均衡: 用来选择一个就近的同样运营商的服务器进行访问可以再DNS服务器中配置 CNAME， 给域名起别名，让本地DNS服务器请求 转到 全局负载均衡器（GSLB： Global Server Load Balance） 进行更复杂的解析可配置第一层 GSLB，解析跟本地DNS服务器相同的运营商， 然后再这个GSLB 同样配置 CNAME， 转到第二层GSLB在第二层 GSLB， 解析本地DNS服务器就近的地址， 返回给本地DNS服务器，相同运营商的最近的服务器IP地址 传统DNS存在的问题 域名缓存问题 1本地服务器 对已经访问过的地址有缓存， 域名换地址后可能还是导向旧地址 域名转发问题 12有些小的运营商不是直接自己访问权威域名服务器 ，而只是进行转发，让其他大的运营商进行域名解析就会导致： A运营商的请求，最后是B运营商访问域名服务器进行域名解析，最后返回B运营商的IP， 导致每次请求都跨运营商, 很慢 出口 NAT 问题 12网络出口的时候，很多机房都会配置 NAT，也即网络地址转换，使得从这个网关出去的包，都换成新的 IP 地址权威DNS服务器，就没办法通过这个地址，来判断客户到底是来自哪个运营商， 可能导致误判运营商，最终跨运营商访问，速度慢 域名更新问题 12本地 DNS 服务器是由不同地区、不同运营商独立部署的在权威 DNS 服务器解析变更的时候，解析结果在全网生效的周期非常漫长 解析延迟问题 1DNS 的查询过程需要递归遍历多个 DNS 服务器， 会有时延 HttpDNS 就是不走传统的 DNS 解析， 而是自己搭建基于 HTTP 协议的 DNS 服务器集群，分布在多个地点和多个运营商。当客户端需要 DNS 解析的时候，直接通过 HTTP 协议进行请求这个服务器集群，得到就近的地址。 1httpDNS需要绕过传统DNS， 不使用默认客户端，往往是手机应用，嵌入支持HttpDNS的客户端 HttpDNS的工作模式 123456在客户端的 SDK 里动态请求服务端，获取 HttpDNS 服务器的 IP 列表，缓存到本地随着不断地解析域名，SDK 也会在本地缓存 DNS 域名解析的结果。 这个缓存是手机应用自己的，可以自己协调 过期更新时间等手机客户端自然知道手机在哪个运营商、哪个地址。由于是直接的 HTTP 通信，HttpDNS 服务器能够准确知道这些信息，因而可以做精准的全局负载均衡。 CDN1234567891011参考思路： 物流的 &quot;就近配送&quot;，在电商网站下单，不是从总部发送快递，从就近仓库发送。 在全球这么多数据中心里部署几台机器，形成一个缓存的集群来缓存部分数据，让用户访问时可以就近访问分布在各个地方的各个数据中心的节点，称为 边缘节点 边缘集群规模比较小，不可能缓存下来所有东西，因而可能无法命中边缘节点之上是： 区域节点再之上是： 中心节点最后还没有就是去 源网站 访问了 CDN分发系统架构： 中心节点 -》 区域节点 -》 边缘节点 客户端如何找到相应的边缘节点进行访问呢？ 1234567跟DNS的全局负载均衡器很像。 在整个多区域，多运营商的分发网络下，找到就近的节点设置了CDN的访问请求： 1. 访问请求网址， 进行第一步域名解析，网址权威DNS服务器上，设置 CNAME，返回CND网络的域名 2. 去 CDN网络域名的 权威DNS服务器上，在这个权威DNS服务器上，设置 CNAME，返回CND的全局负载均衡解析器 3. 去 全局负载均衡解析器， 根据 全局负载均衡器内的策略， 返回合适的缓存服务器。 CND 缓存的内容 1234比较容易缓存，不容易过期静态页面， 图片等流媒体协议： 大量采用了CDN 数据中心VPN Virtual Private Network，虚拟专用网 1234567两个数据中心连接 走公网不安全 租用专线连接太贵 折中办法VPN: 利用开放的公众网络，建立专用数据传输通道，将远程的分支机构、移动办公人员等连接起来 VPN 通过隧道技术在公众网络上仿真一条点到点的专线，是通过利用一种协议来传输另外一种协议的技术这里面涉及三种协议：乘客协议、隧道协议和承载协议 IPsec VPN ( 基于 IP 协议的安全隧道协议 ) 1234561. 公网上信息安全的保证机制 私密性： 加密， 对称加密 完整性： 数据没有被非法篡改，通过对数据进行 hash 运算，产生类似于指纹的数据摘要 真实性： 数据确实是由特定的对端发出，通过身份认证可以保证数据的真实性。 移动网络云计算中的网络云中网络12从物理机到虚拟机： 软件模拟硬件， 主要模拟 CPU、内存、网络、硬盘在数据中心里，用的是 qemu-kvm 虚拟网卡 1234567qemu-kvm 使用 linux中的 TUN/TAP 技术虚拟机 是软件： 打开一个称为 TUN/TAP 的 Char Dev（字符设备文件）， 在物理机上就能看到一张虚拟 TAP 网卡。虚拟机会将打开的这个文件在内部虚拟出一个网卡，所有网络包都往这里发，虚拟机会将网络包转换成为文件流，写入字符设备，就像写入文件一样内核中 TUN/TAP 字符设备驱动会收到这个写入的文件流，交给 TUN/TAP 的虚拟网卡驱动。这个驱动将文件流再次转成网络包，交给 TCP/IP 协议栈，最终从虚拟 TAP 网卡发出来，成为标准的网络包。 虚拟网卡连接到云中 1234567891011121314151617181920212223云计算中的网络注意点： 共享： 每个虚拟机一个或多个虚拟网卡，但物理机上只有有限几个网卡，多虚拟网卡如何共享同一个出口？ 隔离： 安全隔离-两个虚拟机两个用户 ， 流量隔离-两个虚拟机，一个疯狂下载另一个直接没网 互通： 一个用户两天虚拟机，在一个物理机或两个物理机， 如何通信？ 灵活： 虚拟机可能经常创建删除，在不同物理机上飘，有的互通有的不同，需要灵活配置 共享和互通问题： 理解物理机是大学宿舍，虚拟机是个人电脑，之间连通需要交换机 虚拟的交换机： Linux 上的命令 brctl， 创建虚拟网桥brctl addbr br0，然后将两个虚拟机的虚拟网卡连接到这个网桥，网段一致就可以通信了 虚拟机连接外网： 桥接： 将物理网卡 也连接到虚拟交换机上， 跟内部虚拟机的虚拟网卡处于同一网段 NAT: 虚拟交互机和物理网卡之间 有一个NAT设备， 虚拟网络 和 物理网络 不是同一个网络， 还会内置一个虚拟DHCP服务器，为虚拟机分配IP 隔离问题： 1. 一台机器上的两个虚拟机不属于同一个用户， 进行隔离？ brctl 创建的网桥也是支持 VLAN 功能的 设置两个虚拟机的 tag，这样在这个虚拟网桥上，两个虚拟机是不互通的。 2. 跨物理机互通，并且实现 VLAN 的隔离呢？ 命令 vconfig，可以基于物理网卡 eth0 创建带 VLAN 的虚拟网卡, 所有从这个虚拟网卡出去的包，都带这个 VLAN 为每个用户分配不同的 VLAN，在物理机上，基于物理网卡，为每个用户用 vconfig 创建一个带 VLAN 的网卡 不同的用户使用不同的虚拟网桥，带 VLAN 的虚拟网卡也连接到虚拟网桥上。 软件定义网络 （ SDN ） 特点 12345678910111213141516171819202122232425262728293031控制和转发分离控制平面与转发平面之间的开放接口逻辑上的集中控制``` - 实现 ( openFlow, openvSwitch )```textOpenFlow 是 SDN 控制器和网络设备之间互通的南向接口协议OpenvSwitch 用于创建软件的虚拟交换机, 支持 openFlow协议硬件交换机也支持 openFlow协议，从而实现 虚拟机和物理机 被SDN统一控制网络物理SDN 控制器是如何通过 OpenFlow 协议控制网络的呢？ 在 OpenvSwitch 里面，有一个流表规则，任何通过这个交换机的包，都会经过这些规则进行处理，从而接收、转发、放弃 流表： 多个表格，每个表格多行， 每一行 （ 匹配规则，优先级，执行动作 ） 规则覆盖 TCP/IP 协议栈的四层 物理层： 匹配规则： 从哪个口进来 执行动作： 从哪个口出去 MAC层： 匹配规则： 源/目标 MAC 地址， 所属 VLAN 执行动作： 修改 源/目标 MAC 地址， 修改，删除 VLAN， MAC地址学习 网络层： 匹配规则： 源/目标 IP地址 执行动作： 修改 源/目标 IP地址 传输层： 匹配规则； 源/目标 端口 执行动作： 修改 源/目标 端口 网络安全123共有云上的端口的 安全守护措施： 采用 ACL（Access Control List，访问控制列表）来控制 IP 和端口 设置规则，指定IP可以访问开放接口 - 安全组 网络包进入机器后的流程 1234561. 拿下MAC头，查看是否是自己的，是就继续2. 拿下IP头，获取其中的目标IP， 开始进行路由判断，判断之前的节点称为： PREROUTING（路由之前）3. 如果IP是自己的，发给上面的传输层， 这个节点称为： INPUT4. 如果不是自己的，转发出去， 这个几点称为： FORWARD 5. 上传处理完成会返回一个处理结果，处理结果会发出去，这个节点称为： OUTPUT6. 转发还是发出去， 都是在路由判断之后，最后一个节点为： POSTROUTING 上诉五个重要节点： 123linux内核，框架Netfilter， 可以在这些节点插入hook函数，截获数据包，对数据包进行干预一个著名的实现： ip_tables 按功能可分为四大类：连接跟踪（conntrack）、数据包的过滤（filter）、网络地址转换（nat）和数据包的修改（mangle） 安全组 123在云上每个虚拟机都自己安装iptables然后设置规则过于麻烦所以在云平台上，一般允许一个或者多个虚拟机属于某个安全组， 而属于不同安全组的虚拟机之间的访问以及外网访问虚拟机，都需要通过安全组进行过滤 云中的网络 Qos （Quality of Service）123网络控制： 进入的方向不能控制，只能通过policy进行丢弃 出去的方向可以控制 网络Qos 的控制方式 123456789101112131415161718主要都是通过队列的方式进行控制一.无类别排队规则 1. pfifo_fast 分为三个优先级的 先入先出队列Band， 根据网络包里面 TOS，判断进入哪个队列。 TOS 4位 16种类型，对应到 三个队列中 2. 随机公平队列 （Stochastic Fair Queuing） 建立很多的 FIFO 的队列，TCP Session 计算 hash 值，根据hash值分配队列， 另一边轮询从队列中拿数据包发送 3. 令牌桶规则 （TBF，Token Bucket Filte） 一个FIFO队列，但需要拿令牌才能发送 二. 基于类别的队列规则 1. 分层令牌桶规则（HTB， Hierarchical Token Bucket） 如何控制 12对于进入的流量，可以设置策略 Ingress policy对于发出的流量，可以设置 QoS 规则 Egress shaping，支持 HTB 容器技术中的网络容器网络 看起来是隔离的技术： namespace （命名空间） 123将全局性的内容，以命名空间隔离进行不重复。网络的 namespace 由 ip netns 命令操作。它可以创建、删除、查询 namespace 用起来是隔离的技术： cgroup (control groups) 1234是 Linux 内核提供的一种可以限制、隔离进程使用的资源机制。","categories":[{"name":"网络协议","slug":"网络协议","permalink":"http://wczj.github.io/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"http://wczj.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}]},{"title":"即时消息技术学习","slug":"即时消息技术学习","date":"2022-02-15T02:19:32.000Z","updated":"2022-02-16T03:06:58.798Z","comments":true,"path":"2022/02/15/即时消息技术学习/","link":"","permalink":"http://wczj.github.io/2022/02/15/%E5%8D%B3%E6%97%B6%E6%B6%88%E6%81%AF%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"IM应用场景 QQ,微信等聊天类场景： 即时通讯 豆瓣, 知乎等社区类场景： 点对点聊天 yy，抖音等直播类场景： 互动，实时弹幕 小米, 京东智能家居类IOT场景：实时监控，远程控制 游戏里场景： 多人互动 交通类场景： 位置共享 教学类场景： 在线白板 基础篇一个完整的IM系统以聊天系统为例 使用者眼中的聊天系统 聊天的参与需要用户，所以需要有一个用户账号，用来给用户提供唯一标识，以及头像、昵称等可供设置的选项。 账号和账号之间通过某些方式（比如加好友、互粉等）构成账号间的关系链。 你的好友列表或者聊天对象的列表，我们称为联系人的列表，其中你可以选择一个联系人进行聊天互动等操作。 在聊天互动这个环节产生了消息。 同时你和对方之间的聊天消息记录就组成了一个聊天会话，在会话里能看到你们之间所有的互动消息。 开发者眼中的聊天系统 客户端: 一般是用户用于收发消息的终端设备，内置的客户端程序和服务端进行网络通信，用来承载用户的互动请求和消息接收功能 接入服务： 服务端的门户，为客户端提供消息收发的出入口 主要有四块功能：连接保持、协议解析、Session 维护和消息推送。 业务服务： 真正的消息业务逻辑处理层 业务： 消息的存储、未读数变更、更新最近联系人等 存储服务： 账号信息、关系链，以及消息本身，都需要进行持久化存储。 外部接口服务： 让用户在 App 未打开时，或者在后台运行时，也能接收到新消息 将消息给到第三方外部接口服务，来通过手机操作系统自身的公共连接服务来进行操作系统级的“消息推送” 接入服务 和 业务服务 为什么独立拆分？ 123456接入服务作为消息收发的出入口，必须是一个高可用的服务，保持足够的稳定性是一个必要条件。而业务处理服务由于随着产品需求迭代，变更非常频繁，随时有新业务需要上线重启如果两个合一起， 会导致连接层不稳定将“只负责网络通道维持，不参与业务逻辑，不需要频繁变更的接入层”抽离出来，不管业务逻辑如何调整变化，都不需要接入层进行变更，这样能保证连接层的稳定性，从而整体上提升消息收发的用户体验。 1234接入服务和业务处理服务进行拆分有助于 提升业务开发效率，降低业务开发门槛。接入服务负责处理一切网络通信相关的部分，比如网络的稳定性、通信协议的编解码等负责业务开发的同事就可以更加专注于业务逻辑的处理 IM系统的特性 实时性： 消息实时触达 可靠性： 消息不丢，不重 一致性： 同一条消息，在多人、多终端需要保证展现顺序的一致性 安全性： 数据传输安全，数据存储安全，消息内容安全 其他： 省电，省流量等 为一个已有APP加上实时通信功能以点对点为例 消息存储: 消息内容，消息索引 12345消息参与者有两个： 发送方， 接收方收发双方的历史消息独立， 即发送方删除消息，接收方仍有这条消息消息内容表： 存储消息维度的一些基本信息，比如消息 ID、消息内容、消息类型、消息产生时间等消息索引表： 收发双方的两个索引通过同一个消息 ID 和这个内容表关联 张三 给 李四 发一条消息 联系人存储 联系人列表只更新存储收发双方的最新一条消息，不存储两人所有的历史消息 12消息索引表的使用场景一般用于查询收发双方的历史聊天记录，是聊天会话维度；而联系人表的使用场景用于查询某一个人最近的所有联系人，是用户全局维度。 消息未读数 12341.用户维度的总未读2.会话维度的会话未读需要支持“消息的多终端漫游”的应用需要在 IM 服务端进行未读存储，不需要支持“消息的多终端漫游”可以选择本地存储即可 轮询，长连接 轮询 12短轮询： 高频http请求。 费电费流量， 服务端资源压力：服务器QPS抗压，存储资源长轮询： 避免高频无用功的问题。 只降低了入口QPS的请求， 对后端存储压力没有减少 长连接 123websocket： 双向通信, 数据交互网络开销低，web原生支持还有各种TCP衍生的： XMPP 协议、MQTT 协议以及各种私有协议 保证消息可靠投递： ACK机制 可靠： 消息不丢，不重 发送消息分为两个部分 1234567891011121314一. 前半部分 1. 用户A 发送消息到 IM服务器 2. 服务器存储消息 3. 服务器返回给用户A确认步骤1，2，3 都可能失败。 通过 超时重传 进行不丢处理， 但如果是步骤3失败，服务器已经存在消息会出现消息重复的问题。 通过 唯一ID 服务端进行去重，进行不重处理 二. IM服务器将 存储的消息 推送给 用户B 问题1： 可能服务器掉电没有将消息推送给客户端B 问题2： 可能服务器已经将消息推送给了客户端B，但客户端B处理出错。 即网络层面消息投递成功，但用户B看不到消息 一般参考TCP的ACK机制， 实现业务层的ACK协议 业务层ACK协议 12345678910111. IM 服务器在推送消息时，携带一个标识 SID（安全标识符，类似 TCP 的 sequenceId）2. 推送出消息后会将当前消息添加到 “待 ACK 消息列表”3. 客户端 B 成功接收完消息后，会给 IM 服务器回一个业务层的 ACK 包，包中携带有本条接收消息的 SID4. IM 服务器接收后，会从“待 ACK 消息列表”记录中删除此条消息，本次推送才算真正结束如果ACK过程失败IM 服务器的“等待 ACK 队列”一般都会维护一个超时计时器，一定时间内如果没有收到用户 B 回的 ACK 包，会从“等待 ACK 队列”中重新取出那条消息进行重推重传后导致的重复问题： 客户端B 根据唯一ID进行去重极端情况: 服务端宕机的同时，客户端没有收到消息。 IM服务器不能进行重传机制。 补救措施： 消息完整性检查 12345用户在重新上线时，让服务端有能力进行完整性检查，发现用户 用户 “有消息丢失” 的情况，就可以重新同步或者修复丢失的数据常见方案 时间戳比对: 客户端发送本地最新时间戳， 服务端对比发送时间戳之后的消息 时间戳可能存在多机器时钟不同步的问题, 所以在实际的实现上，也可以使用全局的自增序列作为版本号来代替 保证消息时序： 消息序号生成器 消息时序一致性： 消息顺序不对会导致语义逻辑出问题 关键问题： 找到一个时序基准，使得我们的消息具备“时序可比较性” 123456789101112131415161718192021222324时序基准： 全局递增的序号生成器 常见的比如 Redis 的原子自增命令 incr，DB 自带的自增 id，或者类似 Twitter 的 snowflake 算法、“时间相关”的分布式序号生成服务等时序基准的可用性问题： 面向高并发和需要保证高可用的场景，考虑这个“全局序号生成器”的可用性问题。 1. 类似 Redis 的原子自增和 DB 的自增 id，都要求在主库上来执行“取号”操作，而主库基本都是单点部署，在可用性上的保障会相对较差 2. 类似 snowflake 算法的时间相关的分布式“序号生成器”，虽然在发号性能上一般问题不大，但在时间精度 或者 时钟一致上有问题 从业务层面考虑，不需要全局递增，如群聊保证群内序号递增就好。 所以能通过哈希规则把压力分散到多个主库实例上，大量降低多群共用一个“ID 生成器”的并发压力。 对于大部分即时消息业务来说，产品层面可以接受消息时序上存在一定的细微误差， 如同一秒内消息不按严格时序，用户无感知。微博的消息就是秒间有序时序基准的误差减少： IM服务器集群部署， 内部逻辑多线程处理。 并不能保证 先到的消息先推送出去 大部分场景业务能接受“小误差的消息乱序”， 这种可以在接收端进行 本地消息整流 但某些特定场景需要IM 服务能保证绝对的时序, 这种只能在服务端进行 消息整流。 例子： 用户A给用户B 发送分手消息然后取关。 如果顺序倒了，会导致取关后消息发送失败 服务端包内整流： 在发送方对多个请求进行业务层合并，多条消息合并成一条； 离线推送整流： 用户上线后 生产者离线消息打包生成packageId，消费者根据每条消息的 packageID 和 seqID 进行整流，最终执行模块只有在一定超时时间内完整有序地收到所有消息才执行最终推送操作 消息接收端整流 根据序号插入会话 安全性： HttpDNS和TLS 传输安全性 123456789开放网络，可能存在问题： DNS 劫持会导致发往 IM 服务的请求被拦截发到其他服务器，导致内容泄露或失效；或者明文传输的消息内容被中间设备劫取后篡改内容，再发往 IM 服务器引起业务错误等问题。主要关注两个问题： “访问入口安全” 和 “传输链路安全”1. 保证访问入口安全：HttpDNS2. 保证传输链路安全：TLS 传输层加密协议 存储安全性 123456服务端存储， 内部人员非法查询，数据库&#x27;拖库&#x27; 问题账号密码存储安全：“单向散列”算法消息内容存储安全：端到端加密 1. 消息内容采用“端到端加密”（E2EE）, 中间任何链路环节都不对消息进行解密。 2. 消息内容不在服务端存储。 消息内容安全性 123456依托于第三方的内容识别服务来进行“风险内容”的防范1. 建立敏感词库，针对文字内容进行安全识别。2. 依托图片识别技术来对色情图片和视频、广告图片、涉政图片等进行识别处置。3. 使用“语音转文字”和 OCR（图片文本识别）来辅助对图片和语音的进一步挖掘识别。4. 通过爬虫技术来对链接内容进行进一步分析，识别“风险外链”。 分布式锁和原子性： 未读消息提醒的正确性 会话未读 总未读 12345从概念上来说： 总未读数 就是所有会话未读数 的 总和但一般实现上： 总未读数 和 会话未读数 进行单独维护总未读数量高频使用， 总未读数不单单包含即时消息的未读，还有其他业务通知的未读 单独维护 总未读数 和 会话未读数带来的 未读数一致性问题 123456维护的总未读数和会话未读数的总和要保持一致保证 未读更新的原子性 分布式锁 支持事务的资源 原子化嵌入脚本 智能心跳机制： 网络的不确定性需要维护好长连接 12345678长连接中间链路断开， 两段无感知需要 &#x27;快速&#x27;，&#x27;不间断&#x27; 感知到 连接可用性的机制： 心跳机制IM服务端： 感知连接的变化，清理无用连接服务端维护一些“用户在线状态”和“所有在线设备”这些信息，便于业务使用。 保持没有无效信息客户端 断线重连，连接保活 心跳监测 实现方式 TCP Keepalive 12345678910TCP 的 Keepalive 作为操作系统的 TCP/IP 协议栈实现的一部分，对于本机的 TCP 连接，会在连接空闲期按一定的频次，自动发送不携带数据的探测报文，来探测对方是否存活。操作系统默认是关闭这个特性的，需要由应用层来开启。默认的三个配置项：心跳周期是 2 小时，失败后再重试 9 次，超时时间 75s 。 可调整优点： 不需要其他开发工作量，上层应用只需要处理探测后的连接异常情况即可 心跳包不携带数据，带宽资源的浪费也是最少的。缺陷: 比如心跳间隔灵活性较差，一台服务器某一时间只能调整为固定间隔的心跳 另外 TCP Keepalive 虽然能够用于连接层存活的探测，但并不代表真正的应用层处于可用状态。 应用层心跳 1客户端每隔一定时间间隔，向 IM 服务端发送一个业务层的数据包告知自身存活 智能心跳 123456国内移动网络场景下，各个地方运营商在不同的网络类型下 NAT 超时的时间差异性很大用固定频率的应用层心跳在实现上虽然相对较为简单，但为了避免 NAT 超时，只能将心跳间隔设置为小于所有网络环境下 NAT 超时的最短时间所谓智能心跳，就是让心跳间隔能够根据网络环境来自动调整，通过不断自动调整心跳间隔的方式，逐步逼近 NAT 超时临界点，在保证 NAT 不超时的情况下尽量节约设备资源需要不断尝试， 会从一定程度上降低“超时确认阶段”连接的可用性 场景篇分布式一致性， 多端漫游 用户在任意一个设备登录后，都能获取到历史的聊天记录。 12345收发的消息在多个终端漫游，两个前置条件： 设备维度的在线状态 多个终端同时登录并在线的用户，可以让 IM 服务端在收到消息后推给接收方的多台设备，也推给发送方的其他登录设备。 离线消息存储 当用户的离线设备上线时，就能够从服务端的存储中获取到离线期间收发的消息 自动智能扩缩容： 直播互动场景中的峰值流量的应对 直播互动的流量峰值具有“短时间快速聚集”的突发性，流量紧随着主播的开播和结束而剧烈波动 12345678消息下推的并发峰值， 理论： 点对点： 如果两个人每 10 秒说一句话，实际上每秒的消息下推数只有 0.1 500人群聊： 群里每个人也是每 10 秒说一句话，实际每秒的消息下推数是 500 / 10 * 500 = 25000； 10万人在线直播互动： 如果直播间里每个人也每 10 秒说一句话，实际每秒可产生的消息下推数就是 100000 / 10 * 100000 = 10 亿 实际上，10 万人的直播间一般不会有这么高的发言和互动热度，即使能达到，也会在服务端进行限流和选择性丢弃。一个是考虑服务端的承受能力基本不可能达到这个量级，另一方面，即使消息能全部推下去，客户端也处理不了每秒一万条消息的接收，对客户端来说，一般每秒接收几十条消息就已经是极限了 直播互动挑战： 高并发压力 在线状态本地化 12345678910压力： 消息下推环节中消息从一条扇出成十万条。 是消息扇出后的推送普通聊天场景的扇出逻辑： 查询聊天接收方在哪台接入服务器，然后把消息投递过去，最后由接入服务器通过长连接进行投递问题： 普通聊天场景，为了进行精准投递避免资源浪费，一般会维护一个中央的“在线状态&quot;，逻辑层在这里查询，然后投递到对应网关机 但在直播互动，10万人次的房间，查询量级大 优化: 每个网关机维护本机的连接用户状态， 每条消息全量发送给所有网关机，由网关机自行判断推送 微服务的拆分 123456789101112下推消息还受制于网关机的带宽、PPS、CPU 等方面的限制，会容易出现单机的瓶颈，因此当有大型直播活动时，还需对这些容易出现瓶颈的服务进行水平扩容。拆分： 核心服务和非核心服务， 对核心服务进行扩容对于核心服务，我们需要隔离出“容易出现瓶颈点的”和“基本不会有瓶颈的”业务。比如： 核心服务： 发弹幕、打赏、送礼、点赞、消息下推等 非核心服务： 直播回放和第三方系统的同步等 然后在核心服务中： 消息的发送行为和处理一般不容易出现瓶颈， 一个 10w 人的直播间里每秒的互动行为一般超不过 1000 自动扩缩容 1234监控服务或者机器的一些关键指标， 进行自动扩缩容 业务性能指标： 比如直播间人数、发消息和信令的 QPS 与耗时、消息收发延迟等； 机器性能指标： 主要是通用化的机器性能指标，包括带宽、PPS、系统负载、IOPS 等 智能负载均衡 1234在建立长连接前，客户端先通过一个入口调度服务来查询本次连接应该连接的入口 IP，在这个入口调度服务里根据具体后端接入层机器的具体业务和机器的性能指标，来实时计算调度的权重负载低的机器权重值高，会被入口调度服务作为优先接入 IP 下发；负载高的机器权重值低，后续新的连接接入会相对更少。而不单纯是轮询负载，会导致有的机器承载了很多连接，有的则很少 服务高可用：保证核心链路稳定性的流控和熔断机制流量控制123456789101112流控常用算法： 漏桶算法 控制数据注入到网络的速率，平滑网络上的突发流量 它模拟的是一个漏水的桶，所有外部的水都先放进这个水桶，而这个桶以匀速往外均匀漏水，如果水桶满了，外部的水就不能再往桶里倒了 令牌桶算法 控制一个时间窗口内通过的数据量 基本逻辑： 1. 每 1/r 秒往桶里放入一个令牌，r 是用户配置的平均发送速率（也就是每秒会有 r 个令牌放入）。 2. 桶里最多可以放入 b 个令牌，如果桶满了，新放入的令牌会被丢弃。 3. 如果来了 n 个请求，会从桶里消耗掉 n 个令牌。 4. 如果桶里可用令牌数小于 n，那么这 n 个请求会被丢弃掉或者等待新的令牌放入。 全局流控12对于单机瓶颈的问题，通过单机版的流控算法和组件就能很好地实现单机保护但在分布式服务的场景下，很多时候的瓶颈点在于全局的资源或者依赖，这种情况就需要分布式的全局流控来对整体业务进行保护。 123通用流控方案： 一般是通过中央式的资源（如：Redis、Nginx）配合脚本来实现全局的计数器， 或者实现更为复杂的漏桶算法和令牌桶算法，比如可以通过 Redis 的 INCR 命令配合 Lua 实现一个限制 QPS（每秒查询量）的流控组件 细粒度控制 123456在限制 QPS 的时候，流控粒度太粗，没有把 QPS 均匀分摊到每个毫秒里上一秒的最后一个毫秒和下一秒的第一个毫秒都出现了最大流量，就会导致两个毫秒内的 QPS 翻倍简单的处理方式： 把一秒分成若干个 N 毫秒的桶，通过滑动窗口的方式，将流控粒度细化到 N 毫秒 基于滑动窗口来统计 QPS，这样也能避免边界处理时不平滑的问题。 流控依赖资源的瓶颈 12345678910如： 流控使用的 Redis 资源由于访问量太大导致出现不可用的情况方案： 本地批量预取 让使用限流服务的业务进程，每次从远程资源预取多个令牌在本地缓存， 处理限流逻辑时先从本地缓存消耗令牌，本地消费完再触发从远程资源获取到本地缓存， 如果远程获取资源时配额已经不够了，本次请求就会被抛弃 注意： 本地预取可能会导致一定范围的限流误差 比如：上一秒预取的 10 个令牌，在实际业务中下一秒才用到，这样会导致下一秒业务实际的请求量会多一些 所以对于需要精准控制访问量的场景来说可能不是特别适合 自动熔断机制 针对突发流量，除了扩容和流控外，还有一个能有效保护系统整体可用性的手段就是熔断机制。 1234567多依赖的微服务中的雪崩效应: 为了便于管理和隔离，我们经常会对服务进行解耦，独立拆分解耦到不同的微服务中，微服务间通过 RPC 来进行调用和依赖 一个服务变慢，因为依赖关系，上层级联服务性能变差，最终导致系统整体性能的雪崩 一种常见的方式是手动通过开关来进行依赖的降级，微博的很多场景和业务都有用到开关来实现业务或者资源依赖的降级。更智能的方式是自动熔断机制： 开源框架： Netflix 公司出品的 Hystrix，以及目前社区很火热的 Resilience4j 等 “限流”, “熔断机制” 和 “缓存” 一起被列为高并发应用工程实现中的三板斧 进阶篇","categories":[{"name":"IM即时通讯","slug":"IM即时通讯","permalink":"http://wczj.github.io/categories/IM%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/"}],"tags":[{"name":"即时通讯","slug":"即时通讯","permalink":"http://wczj.github.io/tags/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/"}]},{"title":"趣谈linux学习","slug":"趣谈linux学习","date":"2022-02-10T07:08:27.000Z","updated":"2022-02-19T09:20:32.326Z","comments":true,"path":"2022/02/10/趣谈linux学习/","link":"","permalink":"http://wczj.github.io/2022/02/10/%E8%B6%A3%E8%B0%88linux%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"学习地址极客时间·趣谈linux 入门自我测验 答案： A,B,C,D A,B (实模式下运行， 操作系统启动好像就只有刚开始是实模式, 流程不清楚） B () A,B,C,D 不会 linux 学习六个坡 熟练使用linux命令 使用linux进行程序设计 了解linux内核机制 阅读linux源码 实验定制linux组件 落到生产实践 linux综述 电脑零件 外包公司业务和linux子系统对应 子系统： 系统调用 进程管理 内存管理 文件 设备 网络 基础几个系统调用 fork ： 创建进程 （ 由 父进程 调用fork 创建 子进程， 子进程拷贝父进程 ） - 所有会有一个祖宗进程 1234fork 返回值：如果当前进程是子进程，就返回 0；如果当前进程是父进程，就返回子进程的进程号。这样首先在返回值这里就有了一个区分，然后通过 if-else 语句判断，如果是父进程，还接着做原来应该做的事情；如果是子进程，需要请求另一个系统调用execve来执行另一个程序，这个时候，子进程和父进程就彻底分道扬镳了，也就产生了一个分支（fork）了。 分配内存的系统调用，brk 和 mmap 12当分配的内存数量比较小的时候，使用 brk当分配的内存数量比较大的时候，使用 mmap，会重新划分一块区域 对文件操作的系统调用 - 最重要的：open, close, create, lseek, read, write 123456对于已经有的文件，可以使用open打开这个文件，close关闭这个文件；对于没有的文件，可以使用creat创建文件；打开文件以后，可以使用lseek跳到文件的某个位置；可以对文件的内容进行读写，读的系统调用是read，写是writelinux中 一切皆文件 - 优势： 统一操作入口 系统初始化开放架构 计算机核心： CPU CPU和其他设备的连接： 总线（Bus） 设备中最重要的是： 内存 CPU 运算单元： 只管计算 数据单元： 内部缓存和寄存器， 暂时存放数据和运算结果 控制单元： 获得下一条指令，然后执行这条指令。 有一个 指令指针寄存器 ，它里面存放的是下一条指令在内存中的地址 总线 地址总线： 我想拿内存中哪个位置的数据 数据总线： 真正的数据 总线标准 8086 原理 通用寄存器 （8个 16位 ） - CPU数据单元 AX、BX、CX、DX、SP、BP、SI、DI。这些寄存器主要用于在计算过程中暂存数据。 （其中 AX、BX、CX、DX 可以分成两个 8 位的寄存器来使用） CPU控制单元 IP 寄存器就是指令指针寄存器（Instruction Pointer Register)，指向代码段中下一条指令的位置 CS 就是代码段寄存器（Code Segment Register），通过它可以找到代码在内存中的位置 DS 是数据段的寄存器，通过它可以找到数据在内存中的位置。 SS 是栈寄存器（Stack Register）。栈是程序运行中一个特殊的数据结构，数据的存取后进先出，push入栈，pop出栈 32位处理器： 80386总线从16位变为32位， 地址位从20位变为32位 数据单元通用寄存器， 指令指针寄存器 扩展后仍然兼容 但段寄存器不兼容： 原先16位总线询20位地址，是通过左移四位达到目的，段的起始地址只能是16的整除地址 现在32位总线询32位地址，无所谓左移，32位4G内存都能访问到。 段的起始地址放在内存的某个地方。这个地方是一个表格，表格中的一项一项是段描述符（Segment Descriptor）。这里面才是真正的段的起始地址。而段寄存器里面保存的是在这个表格中的哪一项，称为选择子（Selector） 段寄存器 寻址 不兼容咋办？ 模式切换: 不能无缝兼容，通过模式切换兼容 实模式： 当系统刚刚启动的时候，CPU 是处于实模式的，这个时候和原来的模式是兼容的 保护模式： 切换到保护模式，就能够用到 32 位 CPU 更强大的能力 从BIOS 到 bootloaderBIOS BIOS ROM（Read Only Memory，只读存储器） 内存 RAM（Random Access Memory，随机存取存储器 12345678910主板上有部分为 ROM： 固化了一些初始化的程序，就是 BIOS （Basic Input and Output System，基本输入输出系统）内存地址空间： 在 x86 系统中，将空间最上面的 0xF0000 到 0xFFFFF 这 64K 映射给 ROM ， 到这部分地址访问的时候，会访问 ROM当电脑刚加电的时候，会做一些重置的工作 将 CS 设置为 0xFFFF，将 IP 设置为 0x0000，所以第一条指令就会指向 0xFFFF0，正是在 ROM 的范围内。 在这里，有一个 JMP 命令会跳到 ROM 中做初始化工作的代码，于是，BIOS 开始进行初始化的工作。 BIOS： 检查硬件是否完好， 建立一个中断向量表和中断服务程序 bootloader1BIOS 寻找 操作系统， 操作系统在硬盘上，BIOS寻找启动盘， 一般在第一个扇区，占 512 字节，而且以 0xAA55 结束 12345678在Linux 里面有一个工具，叫 Grub2, 就是搞系统启动 1. grub2 第一个要安装的就是 boot.img, 由 boot.S 编译而成，一共 512 字节，正式安装到启动盘的第一个扇区。 这个扇区通常称为 MBR（Master Boot Record，主引导记录 / 扇区）。 BIOS 完成任务后，会将 boot.img 从硬盘加载到内存中的 0x7c00 来运行。 2. boot.img 字节少，做不了太多事， 主要是加载 grub的另一个镜像 core.img 首先加载 core的第一个扇区，diskboot.img, 控制权从boot到diskboot， 加载core的其他镜像， kernel是grub的内核 实模式1M空间太小， lzma_decompress会从 实模式 切换到 保护模式 实模式 切换到 保护模式 工作 启用分段，就是在内存里面建立段描述符表，将寄存器里面的段寄存器变成段选择子，指向某个段描述符，这样就能实现不同进程的切换了 启动分页。能够管理的内存变大了，就需要将内存分成相等大小的块 打开 Gate A20, 8086下是20根地址总线， 到保护模式下， 打开第21根总线，开始工作 总结流程 1BIOS -》引导扇区 boot.img -》 diskboot.img -》 lzma_decompress.img 实模式切换到保护模式 -》 kernel.img 选择操作系统 -》 启动内核 内核初始化 初始进程， 系统创建的第一个进程， 0号进程 中断门， 处理各种中断（系统调用） 内存管理模块， 调度模块 文件系统 1号进程的初始化， 将运行一个用户进程。 有了 内核， 用户 的区分 权限机制：x86将权限分为四个Ring linux使用了 Ring0作为内核态， Ring3作为用户态 系统调用执行 init文件， 内部回复寄存器，指针指向用户态， 进入用户态 用户态祖先进程 2号进程 内核态的进程也应有一个人统一管理起来， 内核态祖先进程 从内核态来看，无论是进程，还是线程，我们都可以统称为任务（Task），都使用相同的数据结构，平放在同一个链表中 系统调用glibc 对系统调用的封装 Linux 提供了 glibc, 里面是系统调用的细节，封装成更加友好的接口。可以直接用 1glibc 算是 办事大厅的中介 进程管理多进程写代码：用系统调用创建进程 写代码： .h 或 .c 文件， 使用fork系统调用 编译： 结果： 程序的二进制文件 （格式： ELF - Executeable and Linkable Format，可执行与可链接格式 ） 过程：","categories":[{"name":"linux","slug":"linux","permalink":"http://wczj.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wczj.github.io/tags/linux/"}]},{"title":"设计模式学习","slug":"设计模式学习","date":"2022-01-24T06:57:48.000Z","updated":"2022-02-11T10:04:31.540Z","comments":true,"path":"2022/01/24/设计模式学习/","link":"","permalink":"http://wczj.github.io/2022/01/24/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"看云 · 设计模式之禅 六大原则单一职责原则 (Single Responsibility Principle) (简称SRP)里氏替换原则 (Liskov Substitution Principle)(简称LSP)面向对象的继承 优点 代码共享，减少创建类的工作量，每个子类都拥有父类的方法和属性； 提高代码的重用性； 提高代码的可扩展性 提高产品或项目的开放性。 缺点 继承是侵入性的。只要继承，就必须拥有父类的所有属性和方法 降低代码的灵活性。子类必须拥有父类的属性和方法 增强了耦合性。当父类的常量、变量和方法被修改时，需要考虑子类的修改。 使用继承时，怎么才能让“利”的因素发挥最大的作用，同时减少“弊”带来的麻烦呢？解决方案是引入里氏替换原则 定义： 第一种 If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T,the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T. 如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o1都代换成o2时，程序P的行为没有发生变化，那么类型S是类型T的子类型 定义： 第二种 Functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it. 所有引用基类的地方必须能透明地使用其子类的对象 1通俗定义： 只要父类能出现的地方子类就可以出现，而且替换为子类也不会产生任何错误或异常， 但是，反过来就不行了，有子类出现的地方，父类未必就能适应 里氏替换原则 定义了良好的继承规范 子类必须完全实现父类的方法 子类可以有自己的个性 覆盖或实现父类的方法时输入参数可以被放大 覆写或实现父类的方法时输出结果可以被缩小 依赖倒置原则 （Dependence Inversion Principle）(简称DIP)定义 高层模块不应该依赖低层模块，两者都应该依赖其抽象 抽象不应该依赖细节 细节应该依赖抽象 1234底层模块: 不可分割原子逻辑高层模块: 原子逻辑的再组装抽象： 接口， 不能直接被实例化细节： 实现类， 实现接口产生的类，可以直接实例化 更精简的定义： 面向接口编程 - OOD（Object-Oriented Design，面向对象设计）的精髓之一 优点减少类间的耦合性，提高系统的稳定性，降低并行开发引起的风险，提高代码的可读性和可维护性 接口隔离原则接口尽量细化，同时接口中的方法尽量少 迪米特法则 （Law of Demeter，LoD）也称 最少知识原则（Least Knowledge Principle，LKP） 核心观念： 类间解耦，弱耦合，只有弱耦合了以后，类的复用率才可以提高 开闭原则应尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来完成变化， 它是为软件实体的未来事件而制定的对现行开发设计进行约束的一个原则 23种设计模式单例模式 定义 12一个类只能生成一个对象, 自行实例化并向整个系统提供这个实例 通过定义一个私有访问权限的构造函数，避免被其他类new出来一个对象 应用 123456789101112内存中只有一个实例优点: 减少了内存开支 减少了系统的性能开销 避免对资源的多重占用 在系统设置全局的访问点，优化和共享资源访问 如： 读取配置，一个写文件动作 缺点： 扩展困难 对测试不利，单例模式没有完成不能测试 工厂方法模式 定义 12Define an interface for creating an object,but let subclasses decide which class to instantiate.Factory Method lets a class defer instantiation to subclasses.（定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。） 优点 123良好封装性： 一个对象创建是有条件约束的，如一个调用者需要一个具体的产品对象，只要知道这个产品的类名，降低模块间的耦合扩展优秀： 在增加产品类的情况下，只要适当地修改具体的工厂类或扩展一个工厂类，就可以完成“拥抱变化” 抽象工厂模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://wczj.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://wczj.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"操作系统-同步互斥","slug":"os-同步互斥","date":"2021-12-15T14:43:53.000Z","updated":"2022-02-15T00:55:45.968Z","comments":true,"path":"2021/12/15/os-同步互斥/","link":"","permalink":"http://wczj.github.io/2021/12/15/os-%E5%90%8C%E6%AD%A5%E4%BA%92%E6%96%A5/","excerpt":"","text":"进程的并发执行进程互斥1234竞争条件: 多进程读写共享数据，结果取决于进程执行的时序进程互斥： 多进程使用共享资源，资源排他性使用。临界资源，互斥资源，共享变量: 一次只能被一个进程使用临界区（互斥区）：各个进程中对某个临界资源实施操作的程序片段 实现进程互斥的方案 软件方案 dekker解法 12两个进程P，Q ， 以标志pturn， qturn 的true，false标识是否想进入临界区的意向然后以turn标志，处理两个都有意向的时候，某一个进行谦让设置为false，让另一个进入临界区 Peterson解法 1234进程i: enter_region(i) 进入临界区 leave_region(i) 硬件方案 屏蔽中断， TSL（XCHG）指令 1 进程同步多个进程发送的事件存在时序关系，需要合作完成一项任务","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"同步互斥","slug":"同步互斥","permalink":"http://wczj.github.io/tags/%E5%90%8C%E6%AD%A5%E4%BA%92%E6%96%A5/"}]},{"title":"操作系统-处理器调度","slug":"os-处理器调度","date":"2021-12-08T13:53:07.000Z","updated":"2021-12-14T16:03:02.476Z","comments":true,"path":"2021/12/08/os-处理器调度/","link":"","permalink":"http://wczj.github.io/2021/12/08/os-%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6/","excerpt":"","text":"CPU调度 概念123456控制，协调 多个进程对CPU的竞争： 即 按一定的调度算法从 就绪队列中 选择一个进程，把CPU使用权交给该进程 如果没有就绪进程，系统会安排一个 系统空闲进程或idle进程系统场景： 多个就绪进程，多个CPU 决策 给哪个进程分配哪个CPU 调度要解决的问题 123WHAT: 按什么原则选择下一个执行的进程 -- 调度算法WHEN： 何时进行选择 -- 调度时机 HOW: 如何让被选中的进程上CPU运行 -- 调度过程 （进程的上下文切换） 调度时机 1234561.进程 正常终止 或 异常终止2.新进程创建 或 等待进程变为就绪进程3.一个进程从运行态进入阻塞态 4.一个进程从运行态变为就绪态 (时钟中断： 时间片到了）即： 内核对 中断/异常/系统调用 处理后返回用户态时， 重新调度 调度过程 1234567891011121314是一个进程让出处理器，由另外一个进程占用处理器的过程包括工作： 切换全局页目录以加载一个新的地址空间 切换内核栈和硬件上下文切换过程包括了： 对原来运行进程各种状态的保存， 对新的进程各种状态的恢复上下文切换开销： 直接开销： 内核完成切换花费的CPU时间 保存和恢复寄存器 切换地址空间（相关指令比较昂贵） 间接开销： 高速缓存（Cache）， 缓冲区缓存（buffer cache）， TLB（translation lookup buffer） 失效 CPU调度算法 不同角度有不同的要求 1234567调度算法衡量指标： 吞吐量： 单位时间完成的进程数量 周转时间： 每个进程从提出请求到完成运行完成的时间 响应时间： 从进程提出请求到第一次回应的时间 其他： CPU利用率： CPU有效工作的时间比率 等待时间： 每个进程在 就绪队列中 等待的时间 调度算法 考虑的问题123456进程控制块PCB： 需要记录哪些 与CPU调度相关的 信息进程优先级 及 就绪队列的组织抢占式调度 与 非抢占式调度I/O密集型 与 CPU密集型 进程时间片 进程优先级 1234567优先级，优先数： 优先数的大小 在不同操作系统中 表示的优先级高低不同 （可能数字小的高，也可能数字大的高）静态优先级： 进程创建时指定，运行过程中不会改变动态优先级： 运行过程中动态变化，如等待时间长的提升优先级 进程就绪队列组织 1234按优先级排队： 根据优先级进入不同的就绪队列其他： 创建时进入最高级队列，时间片轮转，动态降低优先级 抢占式 和 非抢占式 123占用CPU的方式： 抢占式： 有比正在运行的进程 优先级更高的进程进入就绪队列时， 系统可强行剥夺CPU，提供给更高级进程 不可抢占： 某一个进程被调度运行后，除非自身原因放弃CPU，不然能一直运行 I/O密集型 与 CPU密集型 进程 123456进程执行过程的行为划分： I/O密集型： 频繁进行I/O，通常会花费很多时间等待 I/O 的完成 (占用CPU很短的时间就会让出CPU进入I/O等待，所以一般调度系统都会对I/O型进行偏好） CPU密集型（计算密集型）： 需要大量的CPU时间进行计算 （占用CPU时间长） 时间片 12345678一个时间段： 分配给调度到CPU上的进程，允许进程占用CPU运行的时间长度如何选择时间片： 进程切换的开销 对响应时间的要求 就绪进程个数 CPU能力 进程的行为 批处理系统 中采用的 调度算法12345678910111213先来先服务 （ FCFS -- first come first serve ） 先进先出， 非抢占式 （ 问题： 短的在长的后面 ，周转时间长）最短作业优先（ SJF -- shortest job first ） 具有最短完成时间的进程优先执行， 非抢占式 （ 优化周转时间， 问题：长作业一直得不到执行，饥饿现象）最短剩余时间优先 （ SRTN -- shortest remaining time next ） 变为抢占式，一个就绪进程比正在运行进程具有更短的完成时间，进行抢占 （ 优化周转时间 ）最高响应比优先 （ HRRN -- highest response ratio next ） 综合算法， 先计算进程响应比R， 选择R最高的进程进行执行 R = 周转时间 / 处理时间 = （等待时间 + 处理时间）/ 处理时间 = 1 + （等待时间 / 处理时间） 所以相同等待时间，处理时间越多，响应比越小。 即优先级低 然后等待时间变大，响应比就会变大。 即优先级慢慢变高 交互式系统中的调度算法 时间片轮转 （Round Robin） 1234567891011121314为短作业改善平均响应时间解决思路： 周期性切换 每个进程分配一个时间片 时钟中断 - 轮换 时间片分配问题： 太长： 降级为先来先服务， 延长了短作业的响应时间 太短： 进程切换浪费CPU资源， 响应时间变长 设计为： CPU开销 进程切换 为 时间片 的1% 优点： 公平，交互式计算，响应时间快缺点： 进程切换，CPU花费较高。 对不同大小的进程有利，对相同大小的进程响应时间反而会高 最高优先级调度 12345678910111213141516系统进程 优先级 高于 用户进程前台进程 优先级 高于 后台进程操作系统 更偏好 I/O型进程优先级 可以是静态不变的， 也可以是动态调整的。 （以 优先数 决定 优先级）就绪队列按照 优先级 组织实现简单： 不公平 （优先级低的进程 饥饿）基于优先级的抢占式： 优先级反转问题： 一个低优先级进程 持有 高优先级进程需要的资源， 高优先级进程等待低优先级无法执行 解决方案： 设置优先级上限 优先级继承 使用中断禁止 多级反馈队列 调度算法 （feedback） 123456789101112131415unix 的一个分支 BSD 5.3版本采用的调用算法考虑之前的算法之后的一个 择中权衡后的 综合调度算法思路： 设置 多个 就绪队列， 第一级队列优先级最高 给不同就绪队列中的进程分配不同的时间片，第一队列时间片最小； 随着队列优先级降低，时间片增大 按优先级从高到低进行调度 每个队列按 时间片轮转的方式 进行调度 新创建进程就绪后进入 第一级队列 进程用完时间片而放弃CPU，则进入下一级队列 由于阻塞而放弃CPU的进程进入相应的等待队列，等待事件发生，进入原先队列 （队首还是队尾，时间片继续还是重新，可以看情况设计，反应对该类进程的偏好程度） 若是抢占式的： 有更高优先级的进行就绪，可抢占CPU，原运行进程进入 原优先级队列 多处理器调度算法设计考虑12345不仅要选择哪个进程， 还有选择 在哪个处理器上执行进程在多个CPU之间迁移的开销 高速缓存实现，TLB失效 尽可能 让进程在总在同一个CPU上执行 考虑负载均衡问题 （使所有CPU保持均衡忙碌状态） 典型系统使用的调度算法12345UNIX 动态优先数 算法BSD5.3 多级反馈队列LINUX 抢占式调度 (目前是 CFS 完全公平调度算法）Windows 基于优先级的抢占式多任务调度Solaris 综合调度算法 Windows 线程调度1234567调度单位是 线程基于 动态优先级，抢占式调度，结合 时间配额的调整就绪进程 按照 优先级进入相应队列系统总是选择 优先级最高的就绪线程 运行同一优先级的线程， 按时间片轮转进行调度多CPU系统中， 允许多个线程并行运行 引发线程调度的条件 123456789跟之前进程相同的4个条件1.线程 正常终止 或 异常终止2.新线程创建 或 等待线程变为就绪进程3.一个线程从运行态进入阻塞态 4.一个线程从运行态变为就绪态 (时钟中断： 时间片到了）增加条件5. 线程优先级改变6. 线程改变了它的 亲和（affinity）处理机集合 - 线程只能在这几个处理机上执行，其他处理机即便空闲了该线程也不能执行 windows 使用 32 个线程优先级 - 分为 三类 1234561. 实时优先级 （ 31 - 16 ） 不会改变优先级2. 可变优先级 （ 15 - 1 ） 优先级可在一定范围内 升高 或 降低。 （可区分 基本优先级 和 当前优先级 ）3. 系统线程 （ 0 ） 零页线程： 用于对系统中空闲物理页面清零 线程的时间配额 123456一个配额单位的整数线程用完时间配额后，如果没有相同优先级的其他线程， 系统将重新分配一个时间配额给该线程，让它继续运行用法： 两个线程，CPU型，I/O型， 如果直接提高CPU型线程的优先级，则CPU型线程一直运行，I/O型得不到运行。而提高CPU型进程的时间配置，就可以了 线程调度策略 12345678910111. 主动切换 线程等待事件，运行态 转为 阻塞态 。 系统调度新的线程运行2. 抢占 上面线程事件发生唤醒， 优先级高，抢占CPU， 被抢占线程退回就绪队列队首， 如果是实时优先级，重新分配时间配额，如果是可变优先级，分配剩余时间配额3. 时间配额用完 线程优先级没有降低 同优先级就绪队列有其他线程，调度其他线程运行，该线程到队列队尾 没有其他线程，分配新的时间配置，继续运行 线程优先级降低了 选择更高优先级线程执行 线程优先级提升 和 时间配额调整 123456789101112131415Windows调度策略 如何体现对某类线程的倾向性 ？ 如何解决饥饿现象 ？ 如何改善 系统吞吐量，响应时间等整体特征？ 1. 提升线程 优先级 ,针对可变优先级范围 （1-15） I/O操作完成 （临时提升，保证更快上CPU运行处理数据）（会把时间配额减1） 信号量，事件等待结束 前台进程中的线程， 完成一个等待操作 窗口活动 唤醒窗口线程 线程处于就绪态 并超过一定时间没有运行-饥饿 （ 系统线程 &quot;平衡集管理器&quot;， 扫描就绪队列，发现等待超300个时钟周期的饥饿线程， 优先级提升为最大的15，分配4倍的时间配额，线程运行完时间配额后，衰减回原来优先级） 2. 给线程分配一个很大的时间配额","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"处理器调度","slug":"处理器调度","permalink":"http://wczj.github.io/tags/%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6/"}]},{"title":"操作系统-进程与线程","slug":"os-进程与线程","date":"2021-12-02T13:28:54.000Z","updated":"2021-12-08T01:45:51.405Z","comments":true,"path":"2021/12/02/os-进程与线程/","link":"","permalink":"http://wczj.github.io/2021/12/02/os-%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"进程基本概念； 进程状态及状态转换； 进程控制块的作用和内容； 进程控制操作； 进程地址空间与进程映像； 为什么引入线程？线程的应用场景； Web服务器的实现； 线程概念、线程与进程的区别； 线程实现的三种方式； Pthreads线程库及应用； 几个重要的概念：原语、可再入程序。 进程的基本概念12345多道程序设计 : 允许多个程序同时进入内存并运行， 提高系统效率并发环境和并发程序 : 并发环境： 一段时间间隔内， 一个处理器上有 多个程序 处于开始允许但尚未结束的状态 并发程序： 在并发环境中的程序 进程的定义 123456具有独立功能的程序 关于 某个数据集合上的一次运行活动， 系统资源分配和调度的独立单位 （又称 任务） 程序的一次支持过程 正在运行程序的抽象 并发，抽象为一个CPU变成多个CPU 系统资源分配单位，内存，文件。。。独立地址空间 操作系统将 CPU 调度给需要的 进程 进程控制块 PCB （又称 进程描述符，进程属性） 12345678910操作系统 控制和管理进程的数据结构 （保存了操作系统管理进程需要的信息）记录进程的各种属性，描述进程的动态变化过程是操作系统感知进程存在的唯一标志 (一个进程一个PCB)进程表： 所有进程的PCB集合 (操作系统最多有多少个进程是固定的）PCB包含信息 进程的描述信息 进程的控制信息 进程所拥有的资源和使用情况 CPU现场信息 1234567891011121314151617181920212223进程描述信息： 进程标识符（process ID）， 唯一标识，整数 进程名， 通常是可执行文件名，不唯一 用户标识符 （创建进程的用户信息） 进程组关系 （父子进程等） 进程控制信息： 当前状态 优先级 代码执行入口地址 程序的磁盘地址 运行的统计信息（执行时间, 页面调度） 进程间同步和通信 进程的队列指针 进程的消息队列指针所拥有的资源和使用情况： 虚拟地址空间的状况 打开文件的列表CPU现场信息： （进程不运行时，操作系统保存的硬件执行状态） 寄存器值（通用寄存器，程序计数器PC，程序状态字PSW， 栈指针） 指向该进程页表的指针 进程状态及状态转换三种基本状态 运行态 : 占有CPU, 在CPU上执行 就绪态 : 具备运行条件，但是没有空闲CPU，暂时不能执行 等待态 : 因等待某个时间而暂时不能运行(如：等待读盘) - 又称为阻塞态，封锁态，睡眠态 三状态模型 其他状态12345678910创建态： 已经完成进程创建的必要工作： 分配PID，填写PCB 但尚未同意执行该进程（如资源不足）终止态： 终止执行后，完成一些数据统计工作，资源回收工作 挂起态： 用于调节负载 （CPU忙不过来） 进程不占用内存空间， 其进程映像交换到磁盘上 五状态模型 七状态模型 linux状态转换示意图 进程队列按进程所处状态不同对进程进行管理 123为每一类进程建立一个或多个队列 (如处于等待态， 按等待事件不同分多个队列）队列元素为 PCB伴随进程状态的改变，PCB从一个队列进入另一个队列 进程控制完成进程各状态之间的转换 123456789101112131415161718由特定功能的原语实现： （原语： 原子操作，执行的程序不可分割，不可中断） 进程创建原语 进程撤销 进程阻塞，唤醒，挂起，激活 改变优先级 。。。 进程创建原语： 给新进程分配 唯一标识PID， 以及 进程控制块PCB 为进程分配 地址空间 初始化进程控制块 (设置默认值) 设置相应的队列指针 （插入进程队列，如就绪队列） 进程撤销原语： (结束进程） 收回进程所占有的资源 （关闭打开的文件，端口网络连接，回收分配的内存。。。） 撤销该进程的PCB进程阻塞： 处于运行状态的进程，运行过程中期待某一事件发生而未发生时，进程自己执行阻塞原语，有运行态进入阻塞态 Unix常用进程控制操作 （都是系统调用） 1234fork(): 通过 复制调用进程 来创建新的进程， 进程建立进程exec(): 包括一系列系统调用，通过用新的程序代码覆盖原来的地址空间，实现进程执行代码的转换wait(): 初级进程同步操作， 一个进程等待另一个进程结束exit(): 终止一个进程的运行 一些进程的概念12345678进程不同角度的分类： 系统进程 和 用户进程 前台进程 和 后台进程 CPU密集型进程 和 I/O密集型进程进程的层次结构： UNIX： init为根 Windows： 地位相等 进程地址空间1操作系统为 每个进程 分配 独立的相对进程地址空间 进程映像对进程执行活动全过程的静态描述 12345678910由 进程地址空间内容，硬件寄存器内容， 该进程相关的内核数据结构，内核栈 组成用户相关： 进程地址空间（ 代码段，数据段，堆栈，共享库）寄存器相关： 程序计数器，指令寄存器，程序状态寄存器，栈指针，通用寄存器 等的值 内核相关： 静态： PCB 及 各种资源数据结构 动态： 内核栈 （不同进程在进入内核后使用不同的内核栈） 上下文 （context）123456将CPU硬件状态从一个进程换到另外一个进程的 过程称为 上下文切换进程运行时： 硬件状态保存在CPU的寄存器中进程不运行时： 这些寄存器的值保存在 进程控制块PCB中操作系统运行新的进程时： 将PCB相关的值送到对应的寄存器中 线程为什么在进程中引入线程 123应用的需要 - 一个应用一个进程，但同时需要多个任务完成开销的考虑 - 线程开销小，线程切换花费时间少， 线程之间共享内存和文件 性能的考虑 线程的基本概念 1234进程： 资源的拥有者线程： CPU调度单位 (有了线程后继承了进程的基本属性） 在同一进程中增加了多个执行序列（线程） 线程的属性12345678标识符ID状态及状态转换不运行时需要保存的上下文(寄存器值）有自己的栈和栈指针共享进程的地址空间和相关资源可以创建, 撤销 另外一个线程程序开始以 一个单线程进程 运行 线程机制的实现123用户级线程核心级线程混合 - 以上两种方法结合 用户级线程1234567891011121314151617181920实现： 在用户空间 建立 线程库 ： 提供一组管理线程的过程 是运行时系统： 完成线程的管理工作（操作，线程表） 内核管理的还是进程，不知道线程的存在 线程切换不需要 内核态特权 UNIX - 一般就是用户级线程 例子: POSIX线程库 -- PTHREAD POSIX：多线程编程接口， 以线程库方式提供给用户 优点： 线程切换快 调度算法是应用程序特定的 用户级线程可运行在任何操作系统上 （只需要实现线程库）缺点： 内核只将处理器分配给进程， 同一进程的两个线程不能同时运行在两个处理器上 大多数系统调用是阻塞的，因此，由于内核阻塞进程，进程中所有线程也被阻塞 核心级线程彻底改造操作系统 123456内核进行所有线程的管理， 向应用程序提供API接口内核维护进程和线程的上下文线程的切换需要内核支持以线程为基础进行调度例子： Windows 混合模型123456线程的创建在 用户空间 （用线程库完成）线程调度等在 核心态完成实现： 多个用户级线程 多路复用 多个内核级线程例子： Solaris 操作系统 总结进程 123456并发性： 任何进程可以与其他进程 一起向前推荐动态性： 动态产生，动态消亡。 在生命周期内在三种基本状态之间转换独立性： 资源分配 的独立单位 交互性： 进程在执行过程中 与 其他进程产生直接或间接的关系异步性： 每个进程以其 相对独立，不可预知的速度 向前推进进程映像： 程序 + 数据 + 栈（用户栈，内核栈）+ PCB 线程 123多线程的应用场景线程基本概念，属性线程的实现机制 可再入程序 (可重入程序) 的概念 12345指的是可以被多个 进程同时调用的程序，因此对这个程序有限制。 具有固定性质： 它是纯代码的， 在执行过程中这个代码不会改变。 那么如果有改变，就需要调用它的进程提供不同的数据区。改变的内容放在数据区，而代码部分是不再改变的。 那么可再入程序实际上是我们大部分 进程和线程都必须是可再入程序才能去运行","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程与线程","slug":"进程与线程","permalink":"http://wczj.github.io/tags/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"}]},{"title":"操作系统-中断异常机制","slug":"os-中断异常机制","date":"2021-12-01T03:28:54.000Z","updated":"2021-12-08T01:45:51.401Z","comments":true,"path":"2021/12/01/os-中断异常机制/","link":"","permalink":"http://wczj.github.io/2021/12/01/os-%E4%B8%AD%E6%96%AD%E5%BC%82%E5%B8%B8%E6%9C%BA%E5%88%B6/","excerpt":"","text":"操作系统运行环境与运行机制12345操作系统运行环境 CPU状态 中断/异常机制运行机制 系统调用 12345678中央处理器（CPU）： 运算器，控制器，一系列寄存器 以及 高速缓存 构成 两类寄存器： 用户可见寄存器： 高级语言编译器分配使用，减少程序访问内存次数 控制和状态寄存器： 控制处理器的操作，操作系统代码使用常见控制状态寄存器： 程序计数器（PC program counter）：记录将要取出指令的地址 指令寄存器（IR instruction register）： 记录最近取出的指令 程序状态字（PSW program status word） ： 记录处理器的运行状态，如条件码，模式，控制位等信息 操作系统需求 – 保护 123456从特征考虑： 并发，共享 提出要求： 保护和控制硬件提供基本运行机制： 处理器具有特权级别，能在不同的特权级别下运行不同的指令集合 硬件机制可将 OS 和 用户程序隔离 处理器状态（模式） 12现代处理器，cpu状态分为 二，三，或四种在 程序状态字寄存器中，专门设置一位，根据运行程序 对资源和指令的使用权限，设置不同的CPU状态 操作系统需要两种 CPU状态 12345内核态（kernel mode）： 运行操作系统程序 用户态（User mode）： 运行用户程序 特权指令 : 只能操作系统使用非特权指令 ： 用户程序可以使用的指令 （操作系统也能使用） 例子： x86系列处理器 1234567支持 4 个特权级别， 称为特权环： R0， R1， R2， R3R0相当于 内核态R3相当于 用户态R1，R2 介于之间不同级别能运行的指令集合不同目前大部分基于x86的操作系统都只使用了 R0，R3 两个级别 CPU状态之间的转换 123456789用户态 -》 内核态 唯一途径： 中断/异常/陷入机制内核态 -》 用户态 设置程序状态字PSW 一条特殊的指令： 陷入指令 （又称 访管指令， 用户态访问管理态的指令） 提供给用户程序的接口，用户调用操作系统的服务 例如： int， trap， syscall， sysenter/sysexit 中断与异常机制 介绍 12345678910111213141516171819202122232425重要性： 好比汽车的发动机可以说： 操作系统是 由 &quot;中断驱动&quot; 或 &quot;事件驱动&quot; 的主要作用： 处理设备发来的中断请求 捕获用户程序提出的服务请求 防止用户程序执行过程中的破坏性活动 等等 概念： CPU对系统发送的某个事件做成的一种反应 （事件的发送改变处理器的控制流） CPU暂停正在执行的程序， 保留现场，去执行相应的事件处理程序，处理完成后返回断点继续执行 特点： 随机发送 自动处理 可恢复 中断的引入： 支持CPU和设备之间的并行操作异常的引入： CPU执行指令时本身出现的问题 (错误异常处理程序，系统调用) 事件： 中断（外中断）：I/O中断，时钟中断，硬件故障 -- 外部事件 异常（内中断）：系统调用，页故障，保护性异常，断点指令，程序性异常 -- 执行本身程序引发的 工作原理 123456789101112131415软硬件配合完成硬件 -- 中断/异常的响应： 捕获中断源发出的 中断/异常请求，以一定方式响应，将处理器控制器交给特定的处理程序软件 -- 中断/异常的处理程序： 识别 中断/异常类型 并完成相应处理 中断响应： 处理器中有 中断寄存器 响应过程： CPU执行每条指令后扫描中断寄存器，若有中断，将中断触发器内容编码进入PSW相应位（中断码），查中断向量表，执行中断处理程序 中断向量： 一个内存单元 - 存放 中断处理程序入口地址 和 程序运行所需的处理机状态字 中断处理程序： 设计操作系统时，为每一类中断编好处理程序，设置好中断向量表 x86处理器 的中断/异常 123中断： 硬件引发异常： 除零异常等， x86大概20种异常 系统调用： 用户态到内核态的唯一入口，是异常的一种 123456789101112中断控制器（PIC 、 APIC） ：将中断信号转换为 中断向量，引发CPU中断实模式： 中断向量表 存放中断服务程序的入口地址保护模式： 中断描述符表 采用 门（gate）描述符 数据结构 表示中断向量 门描述符类型： 任务门 中断门 （主要使用）： 中断门后 系统自动禁止中断 陷阱门 （主要使用）： 系统不禁止，可继续接收中断 调用门 中断/异常 的硬件处理过程 123456789确定 中断向量i通过IDTR寄存器，找到IDT中断描述符表， 查到第i项 中断描述符通过GDTR寄存器，找到GDT段描述符表，根据中断描述符中的段描述符，从GDT中获取到 中断处理程序的 段基址过程中需要多次特权级别检查检查是否发送特权级别变化，是则堆栈切换 （用户态，内核态切换 - 使用相应权级的堆栈）硬件压栈，保存上下文环境如果是中断门， 则清IF位，禁止继续接收中断， 陷阱门则不管根据 中断描述符的 段内偏移量 和 段描述符的段基址， 获取中断程序入口地址，进入执行 系统调用12345678910用户在编程时可以调用的操作系统功能CPU 从用户态 到 内核态的唯一入口每种操作系统都提供几百种系统调用 进程控制 进程通信 文件使用 目录操作 设备管理 信息维护等等 系统调用， 库函数， 内核函数 概念区分 1234内核函数 是 系统调用 的处理程序库函数 是对 内核函数的分装 （如c库函数）应用程序可以直接调用内核函数来进行系统调用， 但一般是操作 库函数 来进行 系统调用机制的设计 12345678910中断/异常机制 -- 来支持 系统调用的实现一条特殊指令， 陷入指令（又称访管指令） -- 引发异常，完成用户态到内核态的切换系统调用号和参数 -- 每个系统调用事先给定编号（功能号）系统调用表 -- 存放系统调用程序的入口地址参数传递问题： 用户程序参数传递给内核 1. 陷入指令自带参数： 长度有限，参数有限 2. 通过寄存器传递（主要）： 操作系统和用户程序都能访问的寄存器， 数量有限，参数有限 3. 内存中开辟专门的堆栈区 系统调用执行过程 12345CPU 执行到特殊的陷入指令： 中断/异常机制： 硬件保护现场； 查中断向量表， 最终把CPU控制权交给 系统调用总入口程序 系统调用总入口程序： 保存现场；参数保存进内核的堆栈，查系统调用表 把控制权转交给 相应系统调用的处理程序/内核函数 执行系统调用 恢复现场，返回用户程序 基于x86内核的 linux系统调用实现 123456789101112陷入指令 为128号： int $0x80门描述符： 系统初始化时，对IDT表中的128号门初始化对应中断了 门描述符2，3字节标识 段选择符， 0，1，6，7字节为偏移量， 最终能对应到 system_call() 中断总入口 门类型： 15 陷阱门，支持调用过程仍允许接收中断 DPL特权级别： 3， 与用户级别相同， 允许用户进程使用该门描述符 （是用户发起的系统调用，所以必须是3） 执行 int $0x80 命令 特权级别的改变， 切换栈 用户栈 -》 内核栈。 CPU指向新的栈地址 信息压栈， 最后返回使用 找到 系统调用内核函数入口地址，执行","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"中断异常","slug":"中断异常","permalink":"http://wczj.github.io/tags/%E4%B8%AD%E6%96%AD%E5%BC%82%E5%B8%B8/"}]},{"title":"操作系统-简介","slug":"os-简介","date":"2021-12-01T03:28:54.000Z","updated":"2021-12-08T01:45:51.407Z","comments":true,"path":"2021/12/01/os-简介/","link":"","permalink":"http://wczj.github.io/2021/12/01/os-%E7%AE%80%E4%BB%8B/","excerpt":"","text":"学习内容 操作系统结构 中断及系统调用 内存管理 进程及线程 处理机调度 同步互斥 文件系统 I/O子系统 操作系统是什么？是系统软件，一些程序模块的集合 以尽量 有效，合理 的方式，组织和管理计算机的软硬件资源 合理组织计算机的工作流程，控制程序的执行并并向用户提供各种服务功能 用户能够灵活方便的使用计算机，使整个计算机系统高效率运行 关键词： 有效： 系统资源，资源利用率 CPU， I/O设备 合理： 软硬件资源的管理是否公平合理 方便使用： 用户界面 ， 编程接口 操作系统是资源的管理者：（如何管理？） 跟踪记录资源的使用情况 确定资源分配策略--算法 静态分配策略 动态分配策略 实施资源的分配和回收 提高资源利用率 保护资源的使用 协调多个进程对资源请求的冲突 资源管理角度，操作系统的五大基本功能： 进程/线程管理 （CPU管理） 进程线程状态， 控制，同步互斥，通信，调度， 。。。 存储管理 分配/回收，地址转换，存储保护，内存扩充，。。。 文件管理 文件目录，文件操作，磁盘空间，文件存取控制， 。。。 设备管理 设备驱动，分配回收，缓冲技术， 。。。 用户接口 系统命令，编程接口 操作系统是 各种系统服务的提供者 从用户角度看 操作系统为用户提供了一组功能强大，方便易用的命令或系统调用 典型的服务 进程的创建，执行； 文件目录的操作； I/O设备的使用； 各类统计信息， 。。。 对机器硬件的扩展 操作系统的特征 并发： 处理多个同时活动的能力 1234并发问题： 切换，保护，依赖活动间的同步 单CPU： 宏观上： 程序同时执行 微观上： 任何时刻只有一个程序在真正执行 共享： 123456 操作系统和多个用户程序共同使用计算机中的资源操作系统对资源进行合理分配资源在一个时间段内交替被多个进程使用 互斥共享 （打印机 同时共享 （可重入代码，磁盘文件 虚拟 123456一个物理实体 映射为 若干对应的逻辑实体 -- 分时 或 分空间虚拟是 操作系统 管理 系统资源的重要手段， 提高资源利用率CPU -- 每个进程的 &quot;虚处理器&quot;存储器 -- 每个进程都有独立的虚拟地址空间（代码 + 数据 + 堆栈）显示设备 -- 多窗口 或 虚拟终端 随机 123操作系统必须随时对 以不可预测的次序 发生的事件进行响应并处理 进程运行速度不可预知 难以重新系统在某个时刻的状态 操作系统分类 批处理 12345工作方式 1. 系统操作员收集作业，输入系统，系统形成自动转接的连续作业流 2. 启动操作系统，系统依次执行作业，返回作业结果技术： SPOOLING 利用磁盘做缓冲，将输入，计算，输出 组成独立的任务流，使I/O 和 计算 真正并行 分时操作系统 1234时间片 将CPU的时间划分成片段 操作系统以时间片为单位，轮流为终端用户服务，每次服务一个时间片 利用用户错觉，使用户感受不到计算机在服务他人 实时操作系统 12对外部请求在严格时间范围内做出响应高可靠性 个人计算机操作系统 网络操作系统 123基于计算机网络 功能： 网络管理，通信，安全，资源共享，网络应用 追求目标： 互相通信，资源共享 分布式操作系统 123分布式系统： 或以计算机网络为基础，或以多处理机为基础，分别在不同计算机上分布式操作系统： 统一的，多个计算机协作完成一个任务。 自动实现全系统内的任务分配，调度，均衡工作负载处理能力增强，速度更快，可靠性强，具有透明性 嵌入式操作系统 12嵌入式系统： 在各种设备，装置或系统中， 完成特定功能的软硬件系统嵌入式操作系统： 运行在嵌入式系统环境中，对系统及其所控制的资源进行统一调度，指挥的系统软件","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"简介","slug":"简介","permalink":"http://wczj.github.io/tags/%E7%AE%80%E4%BB%8B/"}]},{"title":"linux-software","slug":"linux-software","date":"2021-11-15T01:40:01.000Z","updated":"2021-11-16T05:40:46.059Z","comments":true,"path":"2021/11/15/linux-software/","link":"","permalink":"http://wczj.github.io/2021/11/15/linux-software/","excerpt":"","text":"linux 环境下各种软件的安装centos 安装 v2ray 服务端 （ 个人VPN搭建）1234yum update -y &amp;&amp; yum install curl -y bash &lt;(curl -s -L https://git.io/v2ray.sh) ## 安装脚本v2ray url ## 生成 vmess链接， 导入客户端 systemctl stop firewalld ## 关闭防火墙 安装zsh 和 oh-my-zsh1234567yum install zsh ## 从gitee上获取安装脚本wget https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh## 编辑 install.sh, 修改以下两行REPO=$&#123;REPO:-mirrors/oh-my-zsh&#125; REMOTE=$&#123;REMOTE:-https://gitee.com/$&#123;REPO&#125;.git&#125;","categories":[],"tags":[]},{"title":"code-review","slug":"code-review","date":"2021-11-04T03:51:53.000Z","updated":"2021-11-04T06:26:08.327Z","comments":true,"path":"2021/11/04/code-review/","link":"","permalink":"http://wczj.github.io/2021/11/04/code-review/","excerpt":"","text":"对旧代码进行review 业务说明 (无业务不开发) 设计思路 (一切实现的基础) 代码层次结构 (逻辑清晰的前提) 代码逻辑说明 (想法的具体实现) 代码好的地方 (开发规范执行完好的地方) 代码坏的地方 (开发规范执行不好的地方) 代码实现经典之处 (牛逼大佬值得学习的地方) 代码实现缺陷遗漏之处 (需要牛逼大佬完善的地方) 对新代码如何进行review参考文章 &lt;&lt;如何在团队中做好Code Review&gt;&gt; , 基本全拷贝，去看这篇文章就可以了 好处 互相学习，彼此成就 你有一个苹果，我有一个苹果，彼此交换一下，我们仍然是各有一个苹果；但你有一种思想，我有一种思想，彼此交换，我们就都有了两种思想，甚至更多。 知识共享，自动互备 在大部分团队，尤其是微服务架构的团队。 通常是一个人员负责多个服务/项目， 如果没有code review， 项目中设计的架构知识，业务知识就只存在于项目过程中产出的说明文档了。 （像我们甚至文档都比较少的）很多设计内容基本只存在于开发人员脑子里。 时间久了，自己都会忘，别人要维护就更难了。 code review 的过程， 至少 Reviewer 必须阅读文档，看代码是否实现相同。 知识的传播性更好，基本不会只有一个人了解某个项目的情况了。 统一风格， 提升质量 代码质量等级： 可以编译通过-&gt;可以正常运行-&gt;可以测试通过-&gt;容易阅读-&gt;容易维护 。 Code Review的代码最起码可以达到易阅读这个级别 要做到易阅读，不是只要有Code Review这个环节就可以了，还要有相关的规范，让大家按照同样的工程风格、编码风格去构建项目和编写代码。 统一风格一方面是让大家无论是维护项目还是阅读代码，不用互相适应各自的编码习惯，另外也是给Reviewer一个Code Review的基本依据。 发现Bug不是Code Review的必需品，而是附属品。至于那些低级的问题/bug交给代码扫描工具就可以了，这不是Code Review的职责。 推动code review落地执行工具 gitlab, 每个项目不同角色， 在合并过程进行 code review 开发规范 工程规范 （工程结构，分层方式，命名等） 命令规范 （接口，类，方法名，变量名） 代码格式 （括号，空格，换行，缩进） 注释规范 （规定必要的注释） 日志规范 （合理的记录必要的日志） 各种推荐和不推荐的代码示例 规范学习网址： Go Code Review Comments(Go官方编程规范翻译) Uber 开源的《Go 语言编码规范 Go 最佳实践: 编写可维护 Go 代码 指定流程规范 确定code review 的实施环节 CodeReview建议是放在代码提交测试前，也就是开发人员完成代码开发及自测后将代码提交到测试分支时进行Code Review。毕竟，如果测试通过后再进行CodeReview，如果需要代码变更，势必会增加测试的工作量，甚至影响项目进度。亦或是顶着项目上线的压力，干脆“以后再说”了 以一般的git 工作流程来说， 就是 功能分支 feature 合并到 开发者分支 develop的时候进行 code review 指定角色行为规范 规范的目的： 控制提交Code Review的代码的粒度 控制单次Code Review的时间 提升Commit/MergeRequest描述的质量，减少沟通成本 通过细粒度高频次的方式尽可能利用工程师碎片化的时间进行Code Review，一定程度上保证Code Review的效率。 分享与统计对code review 的过程及结果进行检验 定期分享 我们期望CodeReview可以让工程师之间互相学习的，那么对于一次Code Review通常只有参与的2-3个工程师有互相学习的机会，那么在这个过程中学到的知识，定期的分享出来，既可以加强知识的流动，又可以检查大家究竟有没有在CodeReview过程中学习到知识，或者有没有认真的进行Code Review 至于分享的内容，可以是开发规范中的范例代码，也可以是规范中的正例代码，也可以是针对某个功能实现的最佳算法/最佳实践，也可以是Code Review过程中的争议代码，也可以是自己踩过的坑。 数据统计 为了在一定程度上保证Code Review的效率，我们在规范里是要求参与的工程师： 1231.Developer控制提交Code Review的粒度，或者控制每个Commit的粒度2.Developer要准确清晰的描述所提交的代码 3.Reviewer&amp;Approver要在规定时间内完成Code Review 这些情况纯粹靠人工是无法检验的，还是需要有一定的数据统计。 12如果用Gerrit，可以查询Gerrit的数据库，里面会有Code Review的信息，如果用GitLab，可以通过WebHook或者restful API获取Code Review信息 我们可以做成报表，来展示Code Review的情况： 123451.每人每周Code Review所消耗的时间2.每人每周被Code Review所消耗的平均时间3.超过规定时间的Code Review情况4.代码提交描述字数过少的情况5.等等（根据自己的需要来） 保证code review质量的关键 工程师 对研发规范的认真学习 资深工程师的认真对待","categories":[],"tags":[]},{"title":"hexo_blog","slug":"hexo-blog","date":"2021-11-04T03:40:17.000Z","updated":"2021-11-04T06:56:31.656Z","comments":true,"path":"2021/11/04/hexo-blog/","link":"","permalink":"http://wczj.github.io/2021/11/04/hexo-blog/","excerpt":"","text":"使用 hexo 搭建博客 使用命令 1234hexo init # 空目录初始化hexo g # 生成hexo s # 本地跑服务hexo d # deploy 部署， 上传到 git 插件安装 1234567## 安装 图片 插件npm install https://github.com/CodeFalling/hexo-asset-image --save## 同时修改配置： post_asset_folder: true ## git部署插件安装， 不然会报git的错误npm install hexo-deployer-git --save 123git page 域名保持不懂在 source 下创建 CNAME 文件， 放入 域名","categories":[],"tags":[]}],"categories":[{"name":"算法","slug":"算法","permalink":"http://wczj.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"网络协议","slug":"网络协议","permalink":"http://wczj.github.io/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"IM即时通讯","slug":"IM即时通讯","permalink":"http://wczj.github.io/categories/IM%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/"},{"name":"linux","slug":"linux","permalink":"http://wczj.github.io/categories/linux/"},{"name":"设计模式","slug":"设计模式","permalink":"http://wczj.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://wczj.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"网络协议","slug":"网络协议","permalink":"http://wczj.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"即时通讯","slug":"即时通讯","permalink":"http://wczj.github.io/tags/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/"},{"name":"linux","slug":"linux","permalink":"http://wczj.github.io/tags/linux/"},{"name":"设计模式","slug":"设计模式","permalink":"http://wczj.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"同步互斥","slug":"同步互斥","permalink":"http://wczj.github.io/tags/%E5%90%8C%E6%AD%A5%E4%BA%92%E6%96%A5/"},{"name":"处理器调度","slug":"处理器调度","permalink":"http://wczj.github.io/tags/%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6/"},{"name":"进程与线程","slug":"进程与线程","permalink":"http://wczj.github.io/tags/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"},{"name":"中断异常","slug":"中断异常","permalink":"http://wczj.github.io/tags/%E4%B8%AD%E6%96%AD%E5%BC%82%E5%B8%B8/"},{"name":"简介","slug":"简介","permalink":"http://wczj.github.io/tags/%E7%AE%80%E4%BB%8B/"}]}