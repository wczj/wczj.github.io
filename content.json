{"meta":{"title":"大炮的博客","subtitle":"","description":"","author":"王大炮","url":"http://wczj.github.io","root":"/"},"pages":[],"posts":[{"title":"趣谈网络协议","slug":"趣谈网络协议","date":"2022-02-16T11:53:19.000Z","updated":"2022-02-17T01:58:00.348Z","comments":true,"path":"2022/02/16/趣谈网络协议/","link":"","permalink":"http://wczj.github.io/2022/02/16/%E8%B6%A3%E8%B0%88%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"通信协议综述为什么要学习网络协议？12要打造互联网世界的通天塔，只教给一台机器做什么是不够的，你需要学会教给一大片机器做什么。这就需要网络协议通过网络协议，才能使一大片机器互相协作、共同完成一件事。 网络分层123为什么分层： 复杂的程序都分层，程序设计要求层层封装： 只要是在网络上跑的包，都是完整的。可以有下层没上层，绝对不可能有上层没下层。 ifconfig 命令12345678linux 查看ip地址： ifconfig， ip addr （工具： net-tools 和 iproute2 的故事）大部分的网卡都会有一个 IP 地址, 不是必需IP 地址是一个网卡在网络世界的通讯地址, 相当于门牌号， 不可冲突例： 10.100.122.2 就是一个 IP 地址。这个地址被点分隔为四个部分，每个部分 8 个 bit，所以 IP 地址总共是 32 位 因为不够用，于是就有了 IPv6，也就是上面输出结果里面 inet6 fe80::f816:3eff:fec7:7975/64。这个有 128 位 当初设计哪知道现在会有这么多计算机， 本来 32 位的 IP 地址就不够，还被分成了 5 类 12345对于 A、B、 C 类主要分两部分，前面一部分是网络号，后面一部分是主机号问题： C 类地址能包含的最大主机数量实在太少了，只有 254 个 而 B 类地址能包含的最大主机数量又太多了, 一般企业达不到6万多台机器， 闲着浪费 无类型域间选路（CIDR） 12345678910将 32 位的 IP 地址一分为二，前面是网络号，后面是主机号例： 10.100.122.2/24 这种地址表示形式，就是 CIDR。后面 24 的意思是，32 位中，前 24 位是网络号，后 8 位是主机号 伴随着 CIDR 存在的: 一个是广播地址，10.100.122.255。如果发送这个地址，所有 10.100.122 网络里面的机器都可以收到 另一个是子网掩码，255.255.255.0 将子网掩码和 IP 地址按位计算 AND，就可得到网络号: 如上面例子网络号就是： 10.100.122.0 公有 IP 地址和私有 IP 地址 1234567日常工作现在都是 CIDR, 几乎不用划分 A 类、B 类或者 C 类.私有IP： 是一个组织内部的， 公网之间可以重复公有IP： 是分配的的，需要买在ABC类IP地址中， 私有IP在上图中CIDR中常见的是 /24 的私有IP， 如: 192.168.0.x , 一般私有网络的出口地址，像路由器是 192.168.0.1， 而192.168.0.255是广播地址 D类组播地址 1使用这一类地址，属于某个组的机器都能收到。 ip addr 的继续分析12345678910111213root@test:~# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fec7:7975/64 scope link valid_lft forever preferred_lft forever 123456在 IP 地址的后面有个 scope 对于 eth0 这张网卡来讲，是 global，说明这张网卡是可以对外的，可以接收来自各个地方的包。 对于 lo 来讲，是 host，说明这张网卡仅仅可以供本机相互通信。 lo 全称是 loopback，又称环回接口，往往会被分配到 127.0.0.1 这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。 MAC 地址 在 IP 地址的上一行是 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff，这个被称为 MAC 地址，是一个网卡的物理地址，用十六进制，6 个 byte 表示 12345678910号称 全局唯一， 不会有两个网卡有相同的 MAC 地址，而且网卡自生产出来，就带着这个地址误解：MAC地址唯一，那整个互联网的通信，全部用 MAC 地址好了，只要知道了对方的 MAC 地址，就可以把信息传过去。正解： 一个网络包要从一个地方传到另一个地方，除了要有确定的地址，还需要有定位功能。 而有门牌号码属性的 IP 地址，才是有远程定位功能的MAC 地址更像是身份证，是一个唯一的标识MAC 地址是有一定定位功能的，只不过范围非常有限， 局限在一个子网里面。 例： 从 192.168.0.2/24 访问 192.168.0.3/24 是可以用 MAC 地址的。 网络设备的状态标识 &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; 是干什么的？这个叫做 net_device flags，网络设备的状态标识。 1234UP 表示网卡处于启动的状态；BROADCAST 表示这个网卡有广播地址，可以发送广播包；MULTICAST 表示网卡可以发送多播包；LOWER_UP 表示 L1 是启动的，也即网线插着呢。 MTU1500 MTU1500 是指什么意思呢？是哪一层的概念呢？最大传输单元 MTU 为 1500，这是以太网的默认值。 123MTU 是二层 MAC 层的概念。MAC 层有 MAC 的头，以太网规定正文部分不允许超过 1500 个字节。正文里面有 IP 的头、TCP 的头、HTTP 的头。如果放不下，就需要分片来传输。 qdisc 排队规则 qdisc pfifo_fast 是什么意思呢？qdisc 全称是 queueing discipline，中文叫排队规则。 12345678内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的 qdisc（排队规则）把数据包加入队列队列类型： pfifo : 最简单， 先进先出 pfifo_fast : 它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。 三个波段（band）的优先级也不相同。band 0 最高，band 2 最低。 如果 band 0 里面有数据包，系统就不会处理 band 1 里面的数据包 数据包是按照服务类型（Type of Service，TOS）被分配到三个波段（band）里面的。TOS 是 IP 头里面的一个字段，代表了当前的包是高优先级的，还是低优先级的 总结 IP 是地址，有定位功能；MAC 是身份证，无定位功能； CIDR 可以用来判断是不是本地人； IP 分公有的 IP 和私有的 IP DHCP 和 PXE ： IP怎么来？ 怎么没？如何配置IP地址使用 net-tools 12$ sudo ifconfig eth1 10.0.0.1/24$ sudo ifconfig eth1 up 使用 iproute2： 12$ sudo ip addr add 10.0.0.1/24 dev eth1$ sudo ip link set up eth1 思考： 192.168.1.6 就在你这台机器的旁边，甚至是在同一个交换机上，而你把机器的地址设为了 16.158.23.6。 为什么ping不通？ 123456789原则： 只要是在网络上跑的包，都是完整的，可以有下层没上层，绝对不可能有上层没下层。逻辑分析： 它有自己的源 IP 地址 16.158.23.6，也有目标 IP 地址 192.168.1.6，但是包发不出去，这是因为 MAC 层还没填 Linux 首先会判断，要去的这个地址和我是一个网段的吗，或者和我的一个网卡是同一网段的吗？ 只有是一个网段的，它才会发送 ARP 请求，获取 MAC 地址 如果不是， 这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。 而linux中网关的配置， 网关要和当前的网络至少一个网卡是同一个网段的 1不同系统的配置文件格式不同，但是无非就是 CIDR、子网掩码、广播地址和网关地址。 动态主机配置协议（DHCP）（Dynamic Host Configuration Protocol）123他只需要配置一段共享的 IP 地址。每一台新接入的机器都通过 DHCP 协议，来这个共享的 IP 地址里申请，然后自动配置好就可以了。等人走了，或者用完了，还回去，这样其他的机器也能用。 DHCP 工作方式 新机器加入网络 12345678910111213141516第一步. client进行 DHCP Discover （ 广播 Boot request，我的 MAC 地址是这个，我还没有 IP) 新机器使用 IP 地址 0.0.0.0 发送了一个广播包，目的 IP 地址为 255.255.255.255。广播包封装了 UDP，UDP 封装了 BOOTP。 （其实 DHCP 是 BOOTP 的增强版） 第二步. DHCP server 进行 DHCP offer MAC地址唯一，新MAC地址来了，分配IP地址，并为他保留 。 仍然使用广播地址作为目的地址 第三步，client 进行 DHCP request 新机器得到 offer， 如果有多个DHCP server， 甚至得到多个offer 一般选择最新到达的offer，然后向网络发送一个 DHCP Request 广播数据包，包中包含客户端的 MAC 地址、接受的租约中的 IP 地址、提供此租约的 DHCP 服务器地址等 告诉所有 DHCP Server 它将接受哪一台服务器提供的 IP 地址，告诉其他 DHCP 服务器，谢谢你们的接纳，并请求撤销它们提供的 IP 地址，以便提供给下一个 IP 租用请求者 由于还没有得到 DHCP Server 的最后确认，客户端仍然使用 0.0.0.0 为源 IP 地址、255.255.255.255 为目标地址进行广播第四步， server 进行 DHCP ACK 当 DHCP Server 接收到客户机的 DHCP request 之后， 会广播返回给客户机一个 DHCP ACK 消息包，表明已经接受客户机的选择，并将这一 IP 地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。 广播也是告诉其他server， 该client在我这个server租了IP IP地址的收回和续租 123续租： 客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的 DHCP Server 发送 DHCP request 消息包 客户机接收到该服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新的 TCP/IP 参数，更新自己的配置 自动安装操作系统 预启动执行环境（PXE） 场景： 数据中心里面的管理员可能一下子就拿到几百台空的机器，一个个安装操作系统，会累死的 1234567891011办法： 安装的操作系统放在一个服务器上，让客户端去下载。 问题： 没有操作系统，客户端放哪里？ 解决： 操作系统的启动过程: 首先启动BIOS, 读取硬盘的 MBR 启动扇区，将 GRUB 启动起来；然后将权力交给 GRUB，GRUB 加载内核、加载作为根文件系统的 initramfs 文件；然后将权力交给内核；最后内核启动，初始化整个操作系统 在整个过程中, 只能放在BIOS启动后,因为没安装系统之前，连启动扇区都没有 这个过程叫做预启动执行环境（Pre-boot Execution Environment），简称 PXE。 PXE 协议分为客户端和服务器端，由于还没有操作系统，只能先把客户端放在 BIOS 里面。当计算机启动时，BIOS 把 PXE 客户端调入内存里面，就可以连接到服务端做一些操作了 首先 PXE 的客户端启动起来，发送一个 DHCP 的请求，让 DHCP Server 给它分配一个地址。PXE 客户端有了自己的地址 怎么知道 PXE 服务器在哪里呢？ 在DHCP server 中配置 next-server，指向 PXE 服务器的地址，配置初始启动文件位置 filename 然后TFTP，从 PXE服务器下载 PXE 工作过程","categories":[{"name":"网络协议","slug":"网络协议","permalink":"http://wczj.github.io/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"http://wczj.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}]},{"title":"即时消息技术学习","slug":"即时消息技术学习","date":"2022-02-15T02:19:32.000Z","updated":"2022-02-16T03:06:58.798Z","comments":true,"path":"2022/02/15/即时消息技术学习/","link":"","permalink":"http://wczj.github.io/2022/02/15/%E5%8D%B3%E6%97%B6%E6%B6%88%E6%81%AF%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"IM应用场景 QQ,微信等聊天类场景： 即时通讯 豆瓣, 知乎等社区类场景： 点对点聊天 yy，抖音等直播类场景： 互动，实时弹幕 小米, 京东智能家居类IOT场景：实时监控，远程控制 游戏里场景： 多人互动 交通类场景： 位置共享 教学类场景： 在线白板 基础篇一个完整的IM系统以聊天系统为例 使用者眼中的聊天系统 聊天的参与需要用户，所以需要有一个用户账号，用来给用户提供唯一标识，以及头像、昵称等可供设置的选项。 账号和账号之间通过某些方式（比如加好友、互粉等）构成账号间的关系链。 你的好友列表或者聊天对象的列表，我们称为联系人的列表，其中你可以选择一个联系人进行聊天互动等操作。 在聊天互动这个环节产生了消息。 同时你和对方之间的聊天消息记录就组成了一个聊天会话，在会话里能看到你们之间所有的互动消息。 开发者眼中的聊天系统 客户端: 一般是用户用于收发消息的终端设备，内置的客户端程序和服务端进行网络通信，用来承载用户的互动请求和消息接收功能 接入服务： 服务端的门户，为客户端提供消息收发的出入口 主要有四块功能：连接保持、协议解析、Session 维护和消息推送。 业务服务： 真正的消息业务逻辑处理层 业务： 消息的存储、未读数变更、更新最近联系人等 存储服务： 账号信息、关系链，以及消息本身，都需要进行持久化存储。 外部接口服务： 让用户在 App 未打开时，或者在后台运行时，也能接收到新消息 将消息给到第三方外部接口服务，来通过手机操作系统自身的公共连接服务来进行操作系统级的“消息推送” 接入服务 和 业务服务 为什么独立拆分？ 123456接入服务作为消息收发的出入口，必须是一个高可用的服务，保持足够的稳定性是一个必要条件。而业务处理服务由于随着产品需求迭代，变更非常频繁，随时有新业务需要上线重启如果两个合一起， 会导致连接层不稳定将“只负责网络通道维持，不参与业务逻辑，不需要频繁变更的接入层”抽离出来，不管业务逻辑如何调整变化，都不需要接入层进行变更，这样能保证连接层的稳定性，从而整体上提升消息收发的用户体验。 1234接入服务和业务处理服务进行拆分有助于 提升业务开发效率，降低业务开发门槛。接入服务负责处理一切网络通信相关的部分，比如网络的稳定性、通信协议的编解码等负责业务开发的同事就可以更加专注于业务逻辑的处理 IM系统的特性 实时性： 消息实时触达 可靠性： 消息不丢，不重 一致性： 同一条消息，在多人、多终端需要保证展现顺序的一致性 安全性： 数据传输安全，数据存储安全，消息内容安全 其他： 省电，省流量等 为一个已有APP加上实时通信功能以点对点为例 消息存储: 消息内容，消息索引 12345消息参与者有两个： 发送方， 接收方收发双方的历史消息独立， 即发送方删除消息，接收方仍有这条消息消息内容表： 存储消息维度的一些基本信息，比如消息 ID、消息内容、消息类型、消息产生时间等消息索引表： 收发双方的两个索引通过同一个消息 ID 和这个内容表关联 张三 给 李四 发一条消息 联系人存储 联系人列表只更新存储收发双方的最新一条消息，不存储两人所有的历史消息 12消息索引表的使用场景一般用于查询收发双方的历史聊天记录，是聊天会话维度；而联系人表的使用场景用于查询某一个人最近的所有联系人，是用户全局维度。 消息未读数 12341.用户维度的总未读2.会话维度的会话未读需要支持“消息的多终端漫游”的应用需要在 IM 服务端进行未读存储，不需要支持“消息的多终端漫游”可以选择本地存储即可 轮询，长连接 轮询 12短轮询： 高频http请求。 费电费流量， 服务端资源压力：服务器QPS抗压，存储资源长轮询： 避免高频无用功的问题。 只降低了入口QPS的请求， 对后端存储压力没有减少 长连接 123websocket： 双向通信, 数据交互网络开销低，web原生支持还有各种TCP衍生的： XMPP 协议、MQTT 协议以及各种私有协议 保证消息可靠投递： ACK机制 可靠： 消息不丢，不重 发送消息分为两个部分 1234567891011121314一. 前半部分 1. 用户A 发送消息到 IM服务器 2. 服务器存储消息 3. 服务器返回给用户A确认步骤1，2，3 都可能失败。 通过 超时重传 进行不丢处理， 但如果是步骤3失败，服务器已经存在消息会出现消息重复的问题。 通过 唯一ID 服务端进行去重，进行不重处理 二. IM服务器将 存储的消息 推送给 用户B 问题1： 可能服务器掉电没有将消息推送给客户端B 问题2： 可能服务器已经将消息推送给了客户端B，但客户端B处理出错。 即网络层面消息投递成功，但用户B看不到消息 一般参考TCP的ACK机制， 实现业务层的ACK协议 业务层ACK协议 12345678910111. IM 服务器在推送消息时，携带一个标识 SID（安全标识符，类似 TCP 的 sequenceId）2. 推送出消息后会将当前消息添加到 “待 ACK 消息列表”3. 客户端 B 成功接收完消息后，会给 IM 服务器回一个业务层的 ACK 包，包中携带有本条接收消息的 SID4. IM 服务器接收后，会从“待 ACK 消息列表”记录中删除此条消息，本次推送才算真正结束如果ACK过程失败IM 服务器的“等待 ACK 队列”一般都会维护一个超时计时器，一定时间内如果没有收到用户 B 回的 ACK 包，会从“等待 ACK 队列”中重新取出那条消息进行重推重传后导致的重复问题： 客户端B 根据唯一ID进行去重极端情况: 服务端宕机的同时，客户端没有收到消息。 IM服务器不能进行重传机制。 补救措施： 消息完整性检查 12345用户在重新上线时，让服务端有能力进行完整性检查，发现用户 用户 “有消息丢失” 的情况，就可以重新同步或者修复丢失的数据常见方案 时间戳比对: 客户端发送本地最新时间戳， 服务端对比发送时间戳之后的消息 时间戳可能存在多机器时钟不同步的问题, 所以在实际的实现上，也可以使用全局的自增序列作为版本号来代替 保证消息时序： 消息序号生成器 消息时序一致性： 消息顺序不对会导致语义逻辑出问题 关键问题： 找到一个时序基准，使得我们的消息具备“时序可比较性” 123456789101112131415161718192021222324时序基准： 全局递增的序号生成器 常见的比如 Redis 的原子自增命令 incr，DB 自带的自增 id，或者类似 Twitter 的 snowflake 算法、“时间相关”的分布式序号生成服务等时序基准的可用性问题： 面向高并发和需要保证高可用的场景，考虑这个“全局序号生成器”的可用性问题。 1. 类似 Redis 的原子自增和 DB 的自增 id，都要求在主库上来执行“取号”操作，而主库基本都是单点部署，在可用性上的保障会相对较差 2. 类似 snowflake 算法的时间相关的分布式“序号生成器”，虽然在发号性能上一般问题不大，但在时间精度 或者 时钟一致上有问题 从业务层面考虑，不需要全局递增，如群聊保证群内序号递增就好。 所以能通过哈希规则把压力分散到多个主库实例上，大量降低多群共用一个“ID 生成器”的并发压力。 对于大部分即时消息业务来说，产品层面可以接受消息时序上存在一定的细微误差， 如同一秒内消息不按严格时序，用户无感知。微博的消息就是秒间有序时序基准的误差减少： IM服务器集群部署， 内部逻辑多线程处理。 并不能保证 先到的消息先推送出去 大部分场景业务能接受“小误差的消息乱序”， 这种可以在接收端进行 本地消息整流 但某些特定场景需要IM 服务能保证绝对的时序, 这种只能在服务端进行 消息整流。 例子： 用户A给用户B 发送分手消息然后取关。 如果顺序倒了，会导致取关后消息发送失败 服务端包内整流： 在发送方对多个请求进行业务层合并，多条消息合并成一条； 离线推送整流： 用户上线后 生产者离线消息打包生成packageId，消费者根据每条消息的 packageID 和 seqID 进行整流，最终执行模块只有在一定超时时间内完整有序地收到所有消息才执行最终推送操作 消息接收端整流 根据序号插入会话 安全性： HttpDNS和TLS 传输安全性 123456789开放网络，可能存在问题： DNS 劫持会导致发往 IM 服务的请求被拦截发到其他服务器，导致内容泄露或失效；或者明文传输的消息内容被中间设备劫取后篡改内容，再发往 IM 服务器引起业务错误等问题。主要关注两个问题： “访问入口安全” 和 “传输链路安全”1. 保证访问入口安全：HttpDNS2. 保证传输链路安全：TLS 传输层加密协议 存储安全性 123456服务端存储， 内部人员非法查询，数据库&#x27;拖库&#x27; 问题账号密码存储安全：“单向散列”算法消息内容存储安全：端到端加密 1. 消息内容采用“端到端加密”（E2EE）, 中间任何链路环节都不对消息进行解密。 2. 消息内容不在服务端存储。 消息内容安全性 123456依托于第三方的内容识别服务来进行“风险内容”的防范1. 建立敏感词库，针对文字内容进行安全识别。2. 依托图片识别技术来对色情图片和视频、广告图片、涉政图片等进行识别处置。3. 使用“语音转文字”和 OCR（图片文本识别）来辅助对图片和语音的进一步挖掘识别。4. 通过爬虫技术来对链接内容进行进一步分析，识别“风险外链”。 分布式锁和原子性： 未读消息提醒的正确性 会话未读 总未读 12345从概念上来说： 总未读数 就是所有会话未读数 的 总和但一般实现上： 总未读数 和 会话未读数 进行单独维护总未读数量高频使用， 总未读数不单单包含即时消息的未读，还有其他业务通知的未读 单独维护 总未读数 和 会话未读数带来的 未读数一致性问题 123456维护的总未读数和会话未读数的总和要保持一致保证 未读更新的原子性 分布式锁 支持事务的资源 原子化嵌入脚本 智能心跳机制： 网络的不确定性需要维护好长连接 12345678长连接中间链路断开， 两段无感知需要 &#x27;快速&#x27;，&#x27;不间断&#x27; 感知到 连接可用性的机制： 心跳机制IM服务端： 感知连接的变化，清理无用连接服务端维护一些“用户在线状态”和“所有在线设备”这些信息，便于业务使用。 保持没有无效信息客户端 断线重连，连接保活 心跳监测 实现方式 TCP Keepalive 12345678910TCP 的 Keepalive 作为操作系统的 TCP/IP 协议栈实现的一部分，对于本机的 TCP 连接，会在连接空闲期按一定的频次，自动发送不携带数据的探测报文，来探测对方是否存活。操作系统默认是关闭这个特性的，需要由应用层来开启。默认的三个配置项：心跳周期是 2 小时，失败后再重试 9 次，超时时间 75s 。 可调整优点： 不需要其他开发工作量，上层应用只需要处理探测后的连接异常情况即可 心跳包不携带数据，带宽资源的浪费也是最少的。缺陷: 比如心跳间隔灵活性较差，一台服务器某一时间只能调整为固定间隔的心跳 另外 TCP Keepalive 虽然能够用于连接层存活的探测，但并不代表真正的应用层处于可用状态。 应用层心跳 1客户端每隔一定时间间隔，向 IM 服务端发送一个业务层的数据包告知自身存活 智能心跳 123456国内移动网络场景下，各个地方运营商在不同的网络类型下 NAT 超时的时间差异性很大用固定频率的应用层心跳在实现上虽然相对较为简单，但为了避免 NAT 超时，只能将心跳间隔设置为小于所有网络环境下 NAT 超时的最短时间所谓智能心跳，就是让心跳间隔能够根据网络环境来自动调整，通过不断自动调整心跳间隔的方式，逐步逼近 NAT 超时临界点，在保证 NAT 不超时的情况下尽量节约设备资源需要不断尝试， 会从一定程度上降低“超时确认阶段”连接的可用性 场景篇分布式一致性， 多端漫游 用户在任意一个设备登录后，都能获取到历史的聊天记录。 12345收发的消息在多个终端漫游，两个前置条件： 设备维度的在线状态 多个终端同时登录并在线的用户，可以让 IM 服务端在收到消息后推给接收方的多台设备，也推给发送方的其他登录设备。 离线消息存储 当用户的离线设备上线时，就能够从服务端的存储中获取到离线期间收发的消息 自动智能扩缩容： 直播互动场景中的峰值流量的应对 直播互动的流量峰值具有“短时间快速聚集”的突发性，流量紧随着主播的开播和结束而剧烈波动 12345678消息下推的并发峰值， 理论： 点对点： 如果两个人每 10 秒说一句话，实际上每秒的消息下推数只有 0.1 500人群聊： 群里每个人也是每 10 秒说一句话，实际每秒的消息下推数是 500 / 10 * 500 = 25000； 10万人在线直播互动： 如果直播间里每个人也每 10 秒说一句话，实际每秒可产生的消息下推数就是 100000 / 10 * 100000 = 10 亿 实际上，10 万人的直播间一般不会有这么高的发言和互动热度，即使能达到，也会在服务端进行限流和选择性丢弃。一个是考虑服务端的承受能力基本不可能达到这个量级，另一方面，即使消息能全部推下去，客户端也处理不了每秒一万条消息的接收，对客户端来说，一般每秒接收几十条消息就已经是极限了 直播互动挑战： 高并发压力 在线状态本地化 12345678910压力： 消息下推环节中消息从一条扇出成十万条。 是消息扇出后的推送普通聊天场景的扇出逻辑： 查询聊天接收方在哪台接入服务器，然后把消息投递过去，最后由接入服务器通过长连接进行投递问题： 普通聊天场景，为了进行精准投递避免资源浪费，一般会维护一个中央的“在线状态&quot;，逻辑层在这里查询，然后投递到对应网关机 但在直播互动，10万人次的房间，查询量级大 优化: 每个网关机维护本机的连接用户状态， 每条消息全量发送给所有网关机，由网关机自行判断推送 微服务的拆分 123456789101112下推消息还受制于网关机的带宽、PPS、CPU 等方面的限制，会容易出现单机的瓶颈，因此当有大型直播活动时，还需对这些容易出现瓶颈的服务进行水平扩容。拆分： 核心服务和非核心服务， 对核心服务进行扩容对于核心服务，我们需要隔离出“容易出现瓶颈点的”和“基本不会有瓶颈的”业务。比如： 核心服务： 发弹幕、打赏、送礼、点赞、消息下推等 非核心服务： 直播回放和第三方系统的同步等 然后在核心服务中： 消息的发送行为和处理一般不容易出现瓶颈， 一个 10w 人的直播间里每秒的互动行为一般超不过 1000 自动扩缩容 1234监控服务或者机器的一些关键指标， 进行自动扩缩容 业务性能指标： 比如直播间人数、发消息和信令的 QPS 与耗时、消息收发延迟等； 机器性能指标： 主要是通用化的机器性能指标，包括带宽、PPS、系统负载、IOPS 等 智能负载均衡 1234在建立长连接前，客户端先通过一个入口调度服务来查询本次连接应该连接的入口 IP，在这个入口调度服务里根据具体后端接入层机器的具体业务和机器的性能指标，来实时计算调度的权重负载低的机器权重值高，会被入口调度服务作为优先接入 IP 下发；负载高的机器权重值低，后续新的连接接入会相对更少。而不单纯是轮询负载，会导致有的机器承载了很多连接，有的则很少 服务高可用：保证核心链路稳定性的流控和熔断机制流量控制123456789101112流控常用算法： 漏桶算法 控制数据注入到网络的速率，平滑网络上的突发流量 它模拟的是一个漏水的桶，所有外部的水都先放进这个水桶，而这个桶以匀速往外均匀漏水，如果水桶满了，外部的水就不能再往桶里倒了 令牌桶算法 控制一个时间窗口内通过的数据量 基本逻辑： 1. 每 1/r 秒往桶里放入一个令牌，r 是用户配置的平均发送速率（也就是每秒会有 r 个令牌放入）。 2. 桶里最多可以放入 b 个令牌，如果桶满了，新放入的令牌会被丢弃。 3. 如果来了 n 个请求，会从桶里消耗掉 n 个令牌。 4. 如果桶里可用令牌数小于 n，那么这 n 个请求会被丢弃掉或者等待新的令牌放入。 全局流控12对于单机瓶颈的问题，通过单机版的流控算法和组件就能很好地实现单机保护但在分布式服务的场景下，很多时候的瓶颈点在于全局的资源或者依赖，这种情况就需要分布式的全局流控来对整体业务进行保护。 123通用流控方案： 一般是通过中央式的资源（如：Redis、Nginx）配合脚本来实现全局的计数器， 或者实现更为复杂的漏桶算法和令牌桶算法，比如可以通过 Redis 的 INCR 命令配合 Lua 实现一个限制 QPS（每秒查询量）的流控组件 细粒度控制 123456在限制 QPS 的时候，流控粒度太粗，没有把 QPS 均匀分摊到每个毫秒里上一秒的最后一个毫秒和下一秒的第一个毫秒都出现了最大流量，就会导致两个毫秒内的 QPS 翻倍简单的处理方式： 把一秒分成若干个 N 毫秒的桶，通过滑动窗口的方式，将流控粒度细化到 N 毫秒 基于滑动窗口来统计 QPS，这样也能避免边界处理时不平滑的问题。 流控依赖资源的瓶颈 12345678910如： 流控使用的 Redis 资源由于访问量太大导致出现不可用的情况方案： 本地批量预取 让使用限流服务的业务进程，每次从远程资源预取多个令牌在本地缓存， 处理限流逻辑时先从本地缓存消耗令牌，本地消费完再触发从远程资源获取到本地缓存， 如果远程获取资源时配额已经不够了，本次请求就会被抛弃 注意： 本地预取可能会导致一定范围的限流误差 比如：上一秒预取的 10 个令牌，在实际业务中下一秒才用到，这样会导致下一秒业务实际的请求量会多一些 所以对于需要精准控制访问量的场景来说可能不是特别适合 自动熔断机制 针对突发流量，除了扩容和流控外，还有一个能有效保护系统整体可用性的手段就是熔断机制。 1234567多依赖的微服务中的雪崩效应: 为了便于管理和隔离，我们经常会对服务进行解耦，独立拆分解耦到不同的微服务中，微服务间通过 RPC 来进行调用和依赖 一个服务变慢，因为依赖关系，上层级联服务性能变差，最终导致系统整体性能的雪崩 一种常见的方式是手动通过开关来进行依赖的降级，微博的很多场景和业务都有用到开关来实现业务或者资源依赖的降级。更智能的方式是自动熔断机制： 开源框架： Netflix 公司出品的 Hystrix，以及目前社区很火热的 Resilience4j 等 “限流”, “熔断机制” 和 “缓存” 一起被列为高并发应用工程实现中的三板斧 进阶篇","categories":[{"name":"IM即时通讯","slug":"IM即时通讯","permalink":"http://wczj.github.io/categories/IM%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/"}],"tags":[{"name":"即时通讯","slug":"即时通讯","permalink":"http://wczj.github.io/tags/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/"}]},{"title":"趣谈linux学习","slug":"趣谈linux学习","date":"2022-02-10T07:08:27.000Z","updated":"2022-02-11T09:31:10.640Z","comments":true,"path":"2022/02/10/趣谈linux学习/","link":"","permalink":"http://wczj.github.io/2022/02/10/%E8%B6%A3%E8%B0%88linux%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"学习地址极客时间·趣谈linux 自我测验 答案： A,B,C,D A,B (实模式下运行， 操作系统启动好像就只有刚开始是实模式, 流程不清楚） B () A,B,C,D 不会 linux 学习六个坡 熟练使用linux命令 使用linux进行程序设计 了解linux内核机制 阅读linux源码 实验定制linux组件 落到生产实践 linux综述电脑零件 外包公司业务和linux子系统对应 子系统： 系统调用 进程管理 内存管理 文件 设备 网络 基础几个系统调用 fork ： 创建进程 （ 由 父进程 调用fork 创建 子进程， 子进程拷贝父进程 ） - 所有会有一个祖宗进程 1234fork 返回值：如果当前进程是子进程，就返回 0；如果当前进程是父进程，就返回子进程的进程号。这样首先在返回值这里就有了一个区分，然后通过 if-else 语句判断，如果是父进程，还接着做原来应该做的事情；如果是子进程，需要请求另一个系统调用execve来执行另一个程序，这个时候，子进程和父进程就彻底分道扬镳了，也就产生了一个分支（fork）了。 分配内存的系统调用，brk 和 mmap 12当分配的内存数量比较小的时候，使用 brk当分配的内存数量比较大的时候，使用 mmap，会重新划分一块区域 对文件操作的系统调用 - 最重要的：open, close, create, lseek, read, write 123456对于已经有的文件，可以使用open打开这个文件，close关闭这个文件；对于没有的文件，可以使用creat创建文件；打开文件以后，可以使用lseek跳到文件的某个位置；可以对文件的内容进行读写，读的系统调用是read，写是writelinux中 一切皆文件 - 优势： 统一操作入口 系统初始化开放架构 计算机核心： CPU CPU和其他设备的连接： 总线（Bus） 设备中最重要的是： 内存 CPU 运算单元： 只管计算 数据单元： 内部缓存和寄存器， 暂时存放数据和运算结果 控制单元： 获得下一条指令，然后执行这条指令。 有一个 指令指针寄存器 ，它里面存放的是下一条指令在内存中的地址 总线 地址总线： 我想拿内存中哪个位置的数据 数据总线： 真正的数据 总线标准 8086 原理 通用寄存器 （8个 16位 ） - CPU数据单元 AX、BX、CX、DX、SP、BP、SI、DI。这些寄存器主要用于在计算过程中暂存数据。 （其中 AX、BX、CX、DX 可以分成两个 8 位的寄存器来使用） CPU控制单元 IP 寄存器就是指令指针寄存器（Instruction Pointer Register)，指向代码段中下一条指令的位置 CS 就是代码段寄存器（Code Segment Register），通过它可以找到代码在内存中的位置 DS 是数据段的寄存器，通过它可以找到数据在内存中的位置。 SS 是栈寄存器（Stack Register）。栈是程序运行中一个特殊的数据结构，数据的存取后进先出，push入栈，pop出栈 32位处理器： 80386总线从16位变为32位， 地址位从20位变为32位 数据单元通用寄存器， 指令指针寄存器 扩展后仍然兼容 但段寄存器不兼容： 原先16位总线询20位地址，是通过左移四位达到目的，段的起始地址只能是16的整除地址 现在32位总线询32位地址，无所谓左移，32位4G内存都能访问到。 段的起始地址放在内存的某个地方。这个地方是一个表格，表格中的一项一项是段描述符（Segment Descriptor）。这里面才是真正的段的起始地址。而段寄存器里面保存的是在这个表格中的哪一项，称为选择子（Selector） 段寄存器 寻址 不兼容咋办？ 模式切换: 不能无缝兼容，通过模式切换兼容 实模式： 当系统刚刚启动的时候，CPU 是处于实模式的，这个时候和原来的模式是兼容的 保护模式： 切换到保护模式，就能够用到 32 位 CPU 更强大的能力 从BIOS 到 bootloader BIOS ROM（Read Only Memory，只读存储器） 内存 RAM（Random Access Memory，随机存取存储器 12345678910主板上有部分为 ROM： 固化了一些初始化的程序，就是 BIOS （Basic Input and Output System，基本输入输出系统）内存地址空间： 在 x86 系统中，将空间最上面的 0xF0000 到 0xFFFFF 这 64K 映射给 ROM ， 到这部分地址访问的时候，会访问 ROM当电脑刚加电的时候，会做一些重置的工作 将 CS 设置为 0xFFFF，将 IP 设置为 0x0000，所以第一条指令就会指向 0xFFFF0，正是在 ROM 的范围内。 在这里，有一个 JMP 命令会跳到 ROM 中做初始化工作的代码，于是，BIOS 开始进行初始化的工作。 BIOS： 检查硬件是否完好， 建立一个中断向量表和中断服务程序 bootloader1BIOS 寻找 操作系统， 操作系统在硬盘上，BIOS寻找启动盘， 一般在第一个扇区，占 512 字节，而且以 0xAA55 结束 12345678在Linux 里面有一个工具，叫 Grub2, 就是搞系统启动 1. grub2 第一个要安装的就是 boot.img, 由 boot.S 编译而成，一共 512 字节，正式安装到启动盘的第一个扇区。 这个扇区通常称为 MBR（Master Boot Record，主引导记录 / 扇区）。 BIOS 完成任务后，会将 boot.img 从硬盘加载到内存中的 0x7c00 来运行。 2. boot.img 字节少，做不了太多事， 主要是加载 grub的另一个镜像 core.img 首先加载 core的第一个扇区，diskboot.img, 控制权从boot到diskboot， 加载core的其他镜像， kernel是grub的内核 实模式1M空间太小， lzma_decompress会从 实模式 切换到 保护模式 实模式 切换到 保护模式 工作 启用分段，就是在内存里面建立段描述符表，将寄存器里面的段寄存器变成段选择子，指向某个段描述符，这样就能实现不同进程的切换了 启动分页。能够管理的内存变大了，就需要将内存分成相等大小的块 打开 Gate A20, 8086下是20根地址总线， 到保护模式下， 打开第21根总线，开始工作 总结流程 1BIOS -》引导扇区 boot.img -》 diskboot.img -》 lzma_decompress.img 实模式切换到保护模式 -》 kernel.img 选择操作系统 -》 启动内核 内核初始化 初始进程， 系统创建的第一个进程， 0号进程 中断门， 处理各种中断（系统调用） 内存管理模块， 调度模块 文件系统 1号进程的初始化， 将运行一个用户进程。 有了 内核， 用户 的区分 权限机制：x86将权限分为四个Ring linux使用了 Ring0作为内核态， Ring3作为用户态 系统调用执行 init文件， 内部回复寄存器，指针指向用户态， 进入用户态 用户态祖先进程 2号进程 内核态的进程也应有一个人统一管理起来， 内核态祖先进程 从内核态来看，无论是进程，还是线程，我们都可以统称为任务（Task），都使用相同的数据结构，平放在同一个链表中 系统调用 Linux 提供了 glibc, 里面是系统调用的细节，封装成更加友好的接口。可以直接用","categories":[{"name":"linux","slug":"linux","permalink":"http://wczj.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://wczj.github.io/tags/linux/"}]},{"title":"设计模式学习","slug":"设计模式学习","date":"2022-01-24T06:57:48.000Z","updated":"2022-02-11T10:04:31.540Z","comments":true,"path":"2022/01/24/设计模式学习/","link":"","permalink":"http://wczj.github.io/2022/01/24/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"看云 · 设计模式之禅 六大原则单一职责原则 (Single Responsibility Principle) (简称SRP)里氏替换原则 (Liskov Substitution Principle)(简称LSP)面向对象的继承 优点 代码共享，减少创建类的工作量，每个子类都拥有父类的方法和属性； 提高代码的重用性； 提高代码的可扩展性 提高产品或项目的开放性。 缺点 继承是侵入性的。只要继承，就必须拥有父类的所有属性和方法 降低代码的灵活性。子类必须拥有父类的属性和方法 增强了耦合性。当父类的常量、变量和方法被修改时，需要考虑子类的修改。 使用继承时，怎么才能让“利”的因素发挥最大的作用，同时减少“弊”带来的麻烦呢？解决方案是引入里氏替换原则 定义： 第一种 If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T,the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T. 如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o1都代换成o2时，程序P的行为没有发生变化，那么类型S是类型T的子类型 定义： 第二种 Functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it. 所有引用基类的地方必须能透明地使用其子类的对象 1通俗定义： 只要父类能出现的地方子类就可以出现，而且替换为子类也不会产生任何错误或异常， 但是，反过来就不行了，有子类出现的地方，父类未必就能适应 里氏替换原则 定义了良好的继承规范 子类必须完全实现父类的方法 子类可以有自己的个性 覆盖或实现父类的方法时输入参数可以被放大 覆写或实现父类的方法时输出结果可以被缩小 依赖倒置原则 （Dependence Inversion Principle）(简称DIP)定义 高层模块不应该依赖低层模块，两者都应该依赖其抽象 抽象不应该依赖细节 细节应该依赖抽象 1234底层模块: 不可分割原子逻辑高层模块: 原子逻辑的再组装抽象： 接口， 不能直接被实例化细节： 实现类， 实现接口产生的类，可以直接实例化 更精简的定义： 面向接口编程 - OOD（Object-Oriented Design，面向对象设计）的精髓之一 优点减少类间的耦合性，提高系统的稳定性，降低并行开发引起的风险，提高代码的可读性和可维护性 接口隔离原则接口尽量细化，同时接口中的方法尽量少 迪米特法则 （Law of Demeter，LoD）也称 最少知识原则（Least Knowledge Principle，LKP） 核心观念： 类间解耦，弱耦合，只有弱耦合了以后，类的复用率才可以提高 开闭原则应尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来完成变化， 它是为软件实体的未来事件而制定的对现行开发设计进行约束的一个原则 23种设计模式单例模式 定义 12一个类只能生成一个对象, 自行实例化并向整个系统提供这个实例 通过定义一个私有访问权限的构造函数，避免被其他类new出来一个对象 应用 123456789101112内存中只有一个实例优点: 减少了内存开支 减少了系统的性能开销 避免对资源的多重占用 在系统设置全局的访问点，优化和共享资源访问 如： 读取配置，一个写文件动作 缺点： 扩展困难 对测试不利，单例模式没有完成不能测试 工厂方法模式 定义 12Define an interface for creating an object,but let subclasses decide which class to instantiate.Factory Method lets a class defer instantiation to subclasses.（定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。） 优点 123良好封装性： 一个对象创建是有条件约束的，如一个调用者需要一个具体的产品对象，只要知道这个产品的类名，降低模块间的耦合扩展优秀： 在增加产品类的情况下，只要适当地修改具体的工厂类或扩展一个工厂类，就可以完成“拥抱变化” 抽象工厂模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://wczj.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://wczj.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"操作系统-同步互斥","slug":"os-同步互斥","date":"2021-12-15T14:43:53.000Z","updated":"2022-02-15T00:55:45.968Z","comments":true,"path":"2021/12/15/os-同步互斥/","link":"","permalink":"http://wczj.github.io/2021/12/15/os-%E5%90%8C%E6%AD%A5%E4%BA%92%E6%96%A5/","excerpt":"","text":"进程的并发执行进程互斥1234竞争条件: 多进程读写共享数据，结果取决于进程执行的时序进程互斥： 多进程使用共享资源，资源排他性使用。临界资源，互斥资源，共享变量: 一次只能被一个进程使用临界区（互斥区）：各个进程中对某个临界资源实施操作的程序片段 实现进程互斥的方案 软件方案 dekker解法 12两个进程P，Q ， 以标志pturn， qturn 的true，false标识是否想进入临界区的意向然后以turn标志，处理两个都有意向的时候，某一个进行谦让设置为false，让另一个进入临界区 Peterson解法 1234进程i: enter_region(i) 进入临界区 leave_region(i) 硬件方案 屏蔽中断， TSL（XCHG）指令 1 进程同步多个进程发送的事件存在时序关系，需要合作完成一项任务","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"同步互斥","slug":"同步互斥","permalink":"http://wczj.github.io/tags/%E5%90%8C%E6%AD%A5%E4%BA%92%E6%96%A5/"}]},{"title":"操作系统-处理器调度","slug":"os-处理器调度","date":"2021-12-08T13:53:07.000Z","updated":"2021-12-14T16:03:02.476Z","comments":true,"path":"2021/12/08/os-处理器调度/","link":"","permalink":"http://wczj.github.io/2021/12/08/os-%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6/","excerpt":"","text":"CPU调度 概念123456控制，协调 多个进程对CPU的竞争： 即 按一定的调度算法从 就绪队列中 选择一个进程，把CPU使用权交给该进程 如果没有就绪进程，系统会安排一个 系统空闲进程或idle进程系统场景： 多个就绪进程，多个CPU 决策 给哪个进程分配哪个CPU 调度要解决的问题 123WHAT: 按什么原则选择下一个执行的进程 -- 调度算法WHEN： 何时进行选择 -- 调度时机 HOW: 如何让被选中的进程上CPU运行 -- 调度过程 （进程的上下文切换） 调度时机 1234561.进程 正常终止 或 异常终止2.新进程创建 或 等待进程变为就绪进程3.一个进程从运行态进入阻塞态 4.一个进程从运行态变为就绪态 (时钟中断： 时间片到了）即： 内核对 中断/异常/系统调用 处理后返回用户态时， 重新调度 调度过程 1234567891011121314是一个进程让出处理器，由另外一个进程占用处理器的过程包括工作： 切换全局页目录以加载一个新的地址空间 切换内核栈和硬件上下文切换过程包括了： 对原来运行进程各种状态的保存， 对新的进程各种状态的恢复上下文切换开销： 直接开销： 内核完成切换花费的CPU时间 保存和恢复寄存器 切换地址空间（相关指令比较昂贵） 间接开销： 高速缓存（Cache）， 缓冲区缓存（buffer cache）， TLB（translation lookup buffer） 失效 CPU调度算法 不同角度有不同的要求 1234567调度算法衡量指标： 吞吐量： 单位时间完成的进程数量 周转时间： 每个进程从提出请求到完成运行完成的时间 响应时间： 从进程提出请求到第一次回应的时间 其他： CPU利用率： CPU有效工作的时间比率 等待时间： 每个进程在 就绪队列中 等待的时间 调度算法 考虑的问题123456进程控制块PCB： 需要记录哪些 与CPU调度相关的 信息进程优先级 及 就绪队列的组织抢占式调度 与 非抢占式调度I/O密集型 与 CPU密集型 进程时间片 进程优先级 1234567优先级，优先数： 优先数的大小 在不同操作系统中 表示的优先级高低不同 （可能数字小的高，也可能数字大的高）静态优先级： 进程创建时指定，运行过程中不会改变动态优先级： 运行过程中动态变化，如等待时间长的提升优先级 进程就绪队列组织 1234按优先级排队： 根据优先级进入不同的就绪队列其他： 创建时进入最高级队列，时间片轮转，动态降低优先级 抢占式 和 非抢占式 123占用CPU的方式： 抢占式： 有比正在运行的进程 优先级更高的进程进入就绪队列时， 系统可强行剥夺CPU，提供给更高级进程 不可抢占： 某一个进程被调度运行后，除非自身原因放弃CPU，不然能一直运行 I/O密集型 与 CPU密集型 进程 123456进程执行过程的行为划分： I/O密集型： 频繁进行I/O，通常会花费很多时间等待 I/O 的完成 (占用CPU很短的时间就会让出CPU进入I/O等待，所以一般调度系统都会对I/O型进行偏好） CPU密集型（计算密集型）： 需要大量的CPU时间进行计算 （占用CPU时间长） 时间片 12345678一个时间段： 分配给调度到CPU上的进程，允许进程占用CPU运行的时间长度如何选择时间片： 进程切换的开销 对响应时间的要求 就绪进程个数 CPU能力 进程的行为 批处理系统 中采用的 调度算法12345678910111213先来先服务 （ FCFS -- first come first serve ） 先进先出， 非抢占式 （ 问题： 短的在长的后面 ，周转时间长）最短作业优先（ SJF -- shortest job first ） 具有最短完成时间的进程优先执行， 非抢占式 （ 优化周转时间， 问题：长作业一直得不到执行，饥饿现象）最短剩余时间优先 （ SRTN -- shortest remaining time next ） 变为抢占式，一个就绪进程比正在运行进程具有更短的完成时间，进行抢占 （ 优化周转时间 ）最高响应比优先 （ HRRN -- highest response ratio next ） 综合算法， 先计算进程响应比R， 选择R最高的进程进行执行 R = 周转时间 / 处理时间 = （等待时间 + 处理时间）/ 处理时间 = 1 + （等待时间 / 处理时间） 所以相同等待时间，处理时间越多，响应比越小。 即优先级低 然后等待时间变大，响应比就会变大。 即优先级慢慢变高 交互式系统中的调度算法 时间片轮转 （Round Robin） 1234567891011121314为短作业改善平均响应时间解决思路： 周期性切换 每个进程分配一个时间片 时钟中断 - 轮换 时间片分配问题： 太长： 降级为先来先服务， 延长了短作业的响应时间 太短： 进程切换浪费CPU资源， 响应时间变长 设计为： CPU开销 进程切换 为 时间片 的1% 优点： 公平，交互式计算，响应时间快缺点： 进程切换，CPU花费较高。 对不同大小的进程有利，对相同大小的进程响应时间反而会高 最高优先级调度 12345678910111213141516系统进程 优先级 高于 用户进程前台进程 优先级 高于 后台进程操作系统 更偏好 I/O型进程优先级 可以是静态不变的， 也可以是动态调整的。 （以 优先数 决定 优先级）就绪队列按照 优先级 组织实现简单： 不公平 （优先级低的进程 饥饿）基于优先级的抢占式： 优先级反转问题： 一个低优先级进程 持有 高优先级进程需要的资源， 高优先级进程等待低优先级无法执行 解决方案： 设置优先级上限 优先级继承 使用中断禁止 多级反馈队列 调度算法 （feedback） 123456789101112131415unix 的一个分支 BSD 5.3版本采用的调用算法考虑之前的算法之后的一个 择中权衡后的 综合调度算法思路： 设置 多个 就绪队列， 第一级队列优先级最高 给不同就绪队列中的进程分配不同的时间片，第一队列时间片最小； 随着队列优先级降低，时间片增大 按优先级从高到低进行调度 每个队列按 时间片轮转的方式 进行调度 新创建进程就绪后进入 第一级队列 进程用完时间片而放弃CPU，则进入下一级队列 由于阻塞而放弃CPU的进程进入相应的等待队列，等待事件发生，进入原先队列 （队首还是队尾，时间片继续还是重新，可以看情况设计，反应对该类进程的偏好程度） 若是抢占式的： 有更高优先级的进行就绪，可抢占CPU，原运行进程进入 原优先级队列 多处理器调度算法设计考虑12345不仅要选择哪个进程， 还有选择 在哪个处理器上执行进程在多个CPU之间迁移的开销 高速缓存实现，TLB失效 尽可能 让进程在总在同一个CPU上执行 考虑负载均衡问题 （使所有CPU保持均衡忙碌状态） 典型系统使用的调度算法12345UNIX 动态优先数 算法BSD5.3 多级反馈队列LINUX 抢占式调度 (目前是 CFS 完全公平调度算法）Windows 基于优先级的抢占式多任务调度Solaris 综合调度算法 Windows 线程调度1234567调度单位是 线程基于 动态优先级，抢占式调度，结合 时间配额的调整就绪进程 按照 优先级进入相应队列系统总是选择 优先级最高的就绪线程 运行同一优先级的线程， 按时间片轮转进行调度多CPU系统中， 允许多个线程并行运行 引发线程调度的条件 123456789跟之前进程相同的4个条件1.线程 正常终止 或 异常终止2.新线程创建 或 等待线程变为就绪进程3.一个线程从运行态进入阻塞态 4.一个线程从运行态变为就绪态 (时钟中断： 时间片到了）增加条件5. 线程优先级改变6. 线程改变了它的 亲和（affinity）处理机集合 - 线程只能在这几个处理机上执行，其他处理机即便空闲了该线程也不能执行 windows 使用 32 个线程优先级 - 分为 三类 1234561. 实时优先级 （ 31 - 16 ） 不会改变优先级2. 可变优先级 （ 15 - 1 ） 优先级可在一定范围内 升高 或 降低。 （可区分 基本优先级 和 当前优先级 ）3. 系统线程 （ 0 ） 零页线程： 用于对系统中空闲物理页面清零 线程的时间配额 123456一个配额单位的整数线程用完时间配额后，如果没有相同优先级的其他线程， 系统将重新分配一个时间配额给该线程，让它继续运行用法： 两个线程，CPU型，I/O型， 如果直接提高CPU型线程的优先级，则CPU型线程一直运行，I/O型得不到运行。而提高CPU型进程的时间配置，就可以了 线程调度策略 12345678910111. 主动切换 线程等待事件，运行态 转为 阻塞态 。 系统调度新的线程运行2. 抢占 上面线程事件发生唤醒， 优先级高，抢占CPU， 被抢占线程退回就绪队列队首， 如果是实时优先级，重新分配时间配额，如果是可变优先级，分配剩余时间配额3. 时间配额用完 线程优先级没有降低 同优先级就绪队列有其他线程，调度其他线程运行，该线程到队列队尾 没有其他线程，分配新的时间配置，继续运行 线程优先级降低了 选择更高优先级线程执行 线程优先级提升 和 时间配额调整 123456789101112131415Windows调度策略 如何体现对某类线程的倾向性 ？ 如何解决饥饿现象 ？ 如何改善 系统吞吐量，响应时间等整体特征？ 1. 提升线程 优先级 ,针对可变优先级范围 （1-15） I/O操作完成 （临时提升，保证更快上CPU运行处理数据）（会把时间配额减1） 信号量，事件等待结束 前台进程中的线程， 完成一个等待操作 窗口活动 唤醒窗口线程 线程处于就绪态 并超过一定时间没有运行-饥饿 （ 系统线程 &quot;平衡集管理器&quot;， 扫描就绪队列，发现等待超300个时钟周期的饥饿线程， 优先级提升为最大的15，分配4倍的时间配额，线程运行完时间配额后，衰减回原来优先级） 2. 给线程分配一个很大的时间配额","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"处理器调度","slug":"处理器调度","permalink":"http://wczj.github.io/tags/%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6/"}]},{"title":"操作系统-进程与线程","slug":"os-进程与线程","date":"2021-12-02T13:28:54.000Z","updated":"2021-12-08T01:45:51.405Z","comments":true,"path":"2021/12/02/os-进程与线程/","link":"","permalink":"http://wczj.github.io/2021/12/02/os-%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"进程基本概念； 进程状态及状态转换； 进程控制块的作用和内容； 进程控制操作； 进程地址空间与进程映像； 为什么引入线程？线程的应用场景； Web服务器的实现； 线程概念、线程与进程的区别； 线程实现的三种方式； Pthreads线程库及应用； 几个重要的概念：原语、可再入程序。 进程的基本概念12345多道程序设计 : 允许多个程序同时进入内存并运行， 提高系统效率并发环境和并发程序 : 并发环境： 一段时间间隔内， 一个处理器上有 多个程序 处于开始允许但尚未结束的状态 并发程序： 在并发环境中的程序 进程的定义 123456具有独立功能的程序 关于 某个数据集合上的一次运行活动， 系统资源分配和调度的独立单位 （又称 任务） 程序的一次支持过程 正在运行程序的抽象 并发，抽象为一个CPU变成多个CPU 系统资源分配单位，内存，文件。。。独立地址空间 操作系统将 CPU 调度给需要的 进程 进程控制块 PCB （又称 进程描述符，进程属性） 12345678910操作系统 控制和管理进程的数据结构 （保存了操作系统管理进程需要的信息）记录进程的各种属性，描述进程的动态变化过程是操作系统感知进程存在的唯一标志 (一个进程一个PCB)进程表： 所有进程的PCB集合 (操作系统最多有多少个进程是固定的）PCB包含信息 进程的描述信息 进程的控制信息 进程所拥有的资源和使用情况 CPU现场信息 1234567891011121314151617181920212223进程描述信息： 进程标识符（process ID）， 唯一标识，整数 进程名， 通常是可执行文件名，不唯一 用户标识符 （创建进程的用户信息） 进程组关系 （父子进程等） 进程控制信息： 当前状态 优先级 代码执行入口地址 程序的磁盘地址 运行的统计信息（执行时间, 页面调度） 进程间同步和通信 进程的队列指针 进程的消息队列指针所拥有的资源和使用情况： 虚拟地址空间的状况 打开文件的列表CPU现场信息： （进程不运行时，操作系统保存的硬件执行状态） 寄存器值（通用寄存器，程序计数器PC，程序状态字PSW， 栈指针） 指向该进程页表的指针 进程状态及状态转换三种基本状态 运行态 : 占有CPU, 在CPU上执行 就绪态 : 具备运行条件，但是没有空闲CPU，暂时不能执行 等待态 : 因等待某个时间而暂时不能运行(如：等待读盘) - 又称为阻塞态，封锁态，睡眠态 三状态模型 其他状态12345678910创建态： 已经完成进程创建的必要工作： 分配PID，填写PCB 但尚未同意执行该进程（如资源不足）终止态： 终止执行后，完成一些数据统计工作，资源回收工作 挂起态： 用于调节负载 （CPU忙不过来） 进程不占用内存空间， 其进程映像交换到磁盘上 五状态模型 七状态模型 linux状态转换示意图 进程队列按进程所处状态不同对进程进行管理 123为每一类进程建立一个或多个队列 (如处于等待态， 按等待事件不同分多个队列）队列元素为 PCB伴随进程状态的改变，PCB从一个队列进入另一个队列 进程控制完成进程各状态之间的转换 123456789101112131415161718由特定功能的原语实现： （原语： 原子操作，执行的程序不可分割，不可中断） 进程创建原语 进程撤销 进程阻塞，唤醒，挂起，激活 改变优先级 。。。 进程创建原语： 给新进程分配 唯一标识PID， 以及 进程控制块PCB 为进程分配 地址空间 初始化进程控制块 (设置默认值) 设置相应的队列指针 （插入进程队列，如就绪队列） 进程撤销原语： (结束进程） 收回进程所占有的资源 （关闭打开的文件，端口网络连接，回收分配的内存。。。） 撤销该进程的PCB进程阻塞： 处于运行状态的进程，运行过程中期待某一事件发生而未发生时，进程自己执行阻塞原语，有运行态进入阻塞态 Unix常用进程控制操作 （都是系统调用） 1234fork(): 通过 复制调用进程 来创建新的进程， 进程建立进程exec(): 包括一系列系统调用，通过用新的程序代码覆盖原来的地址空间，实现进程执行代码的转换wait(): 初级进程同步操作， 一个进程等待另一个进程结束exit(): 终止一个进程的运行 一些进程的概念12345678进程不同角度的分类： 系统进程 和 用户进程 前台进程 和 后台进程 CPU密集型进程 和 I/O密集型进程进程的层次结构： UNIX： init为根 Windows： 地位相等 进程地址空间1操作系统为 每个进程 分配 独立的相对进程地址空间 进程映像对进程执行活动全过程的静态描述 12345678910由 进程地址空间内容，硬件寄存器内容， 该进程相关的内核数据结构，内核栈 组成用户相关： 进程地址空间（ 代码段，数据段，堆栈，共享库）寄存器相关： 程序计数器，指令寄存器，程序状态寄存器，栈指针，通用寄存器 等的值 内核相关： 静态： PCB 及 各种资源数据结构 动态： 内核栈 （不同进程在进入内核后使用不同的内核栈） 上下文 （context）123456将CPU硬件状态从一个进程换到另外一个进程的 过程称为 上下文切换进程运行时： 硬件状态保存在CPU的寄存器中进程不运行时： 这些寄存器的值保存在 进程控制块PCB中操作系统运行新的进程时： 将PCB相关的值送到对应的寄存器中 线程为什么在进程中引入线程 123应用的需要 - 一个应用一个进程，但同时需要多个任务完成开销的考虑 - 线程开销小，线程切换花费时间少， 线程之间共享内存和文件 性能的考虑 线程的基本概念 1234进程： 资源的拥有者线程： CPU调度单位 (有了线程后继承了进程的基本属性） 在同一进程中增加了多个执行序列（线程） 线程的属性12345678标识符ID状态及状态转换不运行时需要保存的上下文(寄存器值）有自己的栈和栈指针共享进程的地址空间和相关资源可以创建, 撤销 另外一个线程程序开始以 一个单线程进程 运行 线程机制的实现123用户级线程核心级线程混合 - 以上两种方法结合 用户级线程1234567891011121314151617181920实现： 在用户空间 建立 线程库 ： 提供一组管理线程的过程 是运行时系统： 完成线程的管理工作（操作，线程表） 内核管理的还是进程，不知道线程的存在 线程切换不需要 内核态特权 UNIX - 一般就是用户级线程 例子: POSIX线程库 -- PTHREAD POSIX：多线程编程接口， 以线程库方式提供给用户 优点： 线程切换快 调度算法是应用程序特定的 用户级线程可运行在任何操作系统上 （只需要实现线程库）缺点： 内核只将处理器分配给进程， 同一进程的两个线程不能同时运行在两个处理器上 大多数系统调用是阻塞的，因此，由于内核阻塞进程，进程中所有线程也被阻塞 核心级线程彻底改造操作系统 123456内核进行所有线程的管理， 向应用程序提供API接口内核维护进程和线程的上下文线程的切换需要内核支持以线程为基础进行调度例子： Windows 混合模型123456线程的创建在 用户空间 （用线程库完成）线程调度等在 核心态完成实现： 多个用户级线程 多路复用 多个内核级线程例子： Solaris 操作系统 总结进程 123456并发性： 任何进程可以与其他进程 一起向前推荐动态性： 动态产生，动态消亡。 在生命周期内在三种基本状态之间转换独立性： 资源分配 的独立单位 交互性： 进程在执行过程中 与 其他进程产生直接或间接的关系异步性： 每个进程以其 相对独立，不可预知的速度 向前推进进程映像： 程序 + 数据 + 栈（用户栈，内核栈）+ PCB 线程 123多线程的应用场景线程基本概念，属性线程的实现机制 可再入程序 (可重入程序) 的概念 12345指的是可以被多个 进程同时调用的程序，因此对这个程序有限制。 具有固定性质： 它是纯代码的， 在执行过程中这个代码不会改变。 那么如果有改变，就需要调用它的进程提供不同的数据区。改变的内容放在数据区，而代码部分是不再改变的。 那么可再入程序实际上是我们大部分 进程和线程都必须是可再入程序才能去运行","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程与线程","slug":"进程与线程","permalink":"http://wczj.github.io/tags/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"}]},{"title":"操作系统-中断异常机制","slug":"os-中断异常机制","date":"2021-12-01T03:28:54.000Z","updated":"2021-12-08T01:45:51.401Z","comments":true,"path":"2021/12/01/os-中断异常机制/","link":"","permalink":"http://wczj.github.io/2021/12/01/os-%E4%B8%AD%E6%96%AD%E5%BC%82%E5%B8%B8%E6%9C%BA%E5%88%B6/","excerpt":"","text":"操作系统运行环境与运行机制12345操作系统运行环境 CPU状态 中断/异常机制运行机制 系统调用 12345678中央处理器（CPU）： 运算器，控制器，一系列寄存器 以及 高速缓存 构成 两类寄存器： 用户可见寄存器： 高级语言编译器分配使用，减少程序访问内存次数 控制和状态寄存器： 控制处理器的操作，操作系统代码使用常见控制状态寄存器： 程序计数器（PC program counter）：记录将要取出指令的地址 指令寄存器（IR instruction register）： 记录最近取出的指令 程序状态字（PSW program status word） ： 记录处理器的运行状态，如条件码，模式，控制位等信息 操作系统需求 – 保护 123456从特征考虑： 并发，共享 提出要求： 保护和控制硬件提供基本运行机制： 处理器具有特权级别，能在不同的特权级别下运行不同的指令集合 硬件机制可将 OS 和 用户程序隔离 处理器状态（模式） 12现代处理器，cpu状态分为 二，三，或四种在 程序状态字寄存器中，专门设置一位，根据运行程序 对资源和指令的使用权限，设置不同的CPU状态 操作系统需要两种 CPU状态 12345内核态（kernel mode）： 运行操作系统程序 用户态（User mode）： 运行用户程序 特权指令 : 只能操作系统使用非特权指令 ： 用户程序可以使用的指令 （操作系统也能使用） 例子： x86系列处理器 1234567支持 4 个特权级别， 称为特权环： R0， R1， R2， R3R0相当于 内核态R3相当于 用户态R1，R2 介于之间不同级别能运行的指令集合不同目前大部分基于x86的操作系统都只使用了 R0，R3 两个级别 CPU状态之间的转换 123456789用户态 -》 内核态 唯一途径： 中断/异常/陷入机制内核态 -》 用户态 设置程序状态字PSW 一条特殊的指令： 陷入指令 （又称 访管指令， 用户态访问管理态的指令） 提供给用户程序的接口，用户调用操作系统的服务 例如： int， trap， syscall， sysenter/sysexit 中断与异常机制 介绍 12345678910111213141516171819202122232425重要性： 好比汽车的发动机可以说： 操作系统是 由 &quot;中断驱动&quot; 或 &quot;事件驱动&quot; 的主要作用： 处理设备发来的中断请求 捕获用户程序提出的服务请求 防止用户程序执行过程中的破坏性活动 等等 概念： CPU对系统发送的某个事件做成的一种反应 （事件的发送改变处理器的控制流） CPU暂停正在执行的程序， 保留现场，去执行相应的事件处理程序，处理完成后返回断点继续执行 特点： 随机发送 自动处理 可恢复 中断的引入： 支持CPU和设备之间的并行操作异常的引入： CPU执行指令时本身出现的问题 (错误异常处理程序，系统调用) 事件： 中断（外中断）：I/O中断，时钟中断，硬件故障 -- 外部事件 异常（内中断）：系统调用，页故障，保护性异常，断点指令，程序性异常 -- 执行本身程序引发的 工作原理 123456789101112131415软硬件配合完成硬件 -- 中断/异常的响应： 捕获中断源发出的 中断/异常请求，以一定方式响应，将处理器控制器交给特定的处理程序软件 -- 中断/异常的处理程序： 识别 中断/异常类型 并完成相应处理 中断响应： 处理器中有 中断寄存器 响应过程： CPU执行每条指令后扫描中断寄存器，若有中断，将中断触发器内容编码进入PSW相应位（中断码），查中断向量表，执行中断处理程序 中断向量： 一个内存单元 - 存放 中断处理程序入口地址 和 程序运行所需的处理机状态字 中断处理程序： 设计操作系统时，为每一类中断编好处理程序，设置好中断向量表 x86处理器 的中断/异常 123中断： 硬件引发异常： 除零异常等， x86大概20种异常 系统调用： 用户态到内核态的唯一入口，是异常的一种 123456789101112中断控制器（PIC 、 APIC） ：将中断信号转换为 中断向量，引发CPU中断实模式： 中断向量表 存放中断服务程序的入口地址保护模式： 中断描述符表 采用 门（gate）描述符 数据结构 表示中断向量 门描述符类型： 任务门 中断门 （主要使用）： 中断门后 系统自动禁止中断 陷阱门 （主要使用）： 系统不禁止，可继续接收中断 调用门 中断/异常 的硬件处理过程 123456789确定 中断向量i通过IDTR寄存器，找到IDT中断描述符表， 查到第i项 中断描述符通过GDTR寄存器，找到GDT段描述符表，根据中断描述符中的段描述符，从GDT中获取到 中断处理程序的 段基址过程中需要多次特权级别检查检查是否发送特权级别变化，是则堆栈切换 （用户态，内核态切换 - 使用相应权级的堆栈）硬件压栈，保存上下文环境如果是中断门， 则清IF位，禁止继续接收中断， 陷阱门则不管根据 中断描述符的 段内偏移量 和 段描述符的段基址， 获取中断程序入口地址，进入执行 系统调用12345678910用户在编程时可以调用的操作系统功能CPU 从用户态 到 内核态的唯一入口每种操作系统都提供几百种系统调用 进程控制 进程通信 文件使用 目录操作 设备管理 信息维护等等 系统调用， 库函数， 内核函数 概念区分 1234内核函数 是 系统调用 的处理程序库函数 是对 内核函数的分装 （如c库函数）应用程序可以直接调用内核函数来进行系统调用， 但一般是操作 库函数 来进行 系统调用机制的设计 12345678910中断/异常机制 -- 来支持 系统调用的实现一条特殊指令， 陷入指令（又称访管指令） -- 引发异常，完成用户态到内核态的切换系统调用号和参数 -- 每个系统调用事先给定编号（功能号）系统调用表 -- 存放系统调用程序的入口地址参数传递问题： 用户程序参数传递给内核 1. 陷入指令自带参数： 长度有限，参数有限 2. 通过寄存器传递（主要）： 操作系统和用户程序都能访问的寄存器， 数量有限，参数有限 3. 内存中开辟专门的堆栈区 系统调用执行过程 12345CPU 执行到特殊的陷入指令： 中断/异常机制： 硬件保护现场； 查中断向量表， 最终把CPU控制权交给 系统调用总入口程序 系统调用总入口程序： 保存现场；参数保存进内核的堆栈，查系统调用表 把控制权转交给 相应系统调用的处理程序/内核函数 执行系统调用 恢复现场，返回用户程序 基于x86内核的 linux系统调用实现 123456789101112陷入指令 为128号： int $0x80门描述符： 系统初始化时，对IDT表中的128号门初始化对应中断了 门描述符2，3字节标识 段选择符， 0，1，6，7字节为偏移量， 最终能对应到 system_call() 中断总入口 门类型： 15 陷阱门，支持调用过程仍允许接收中断 DPL特权级别： 3， 与用户级别相同， 允许用户进程使用该门描述符 （是用户发起的系统调用，所以必须是3） 执行 int $0x80 命令 特权级别的改变， 切换栈 用户栈 -》 内核栈。 CPU指向新的栈地址 信息压栈， 最后返回使用 找到 系统调用内核函数入口地址，执行","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"中断异常","slug":"中断异常","permalink":"http://wczj.github.io/tags/%E4%B8%AD%E6%96%AD%E5%BC%82%E5%B8%B8/"}]},{"title":"操作系统-简介","slug":"os-简介","date":"2021-12-01T03:28:54.000Z","updated":"2021-12-08T01:45:51.407Z","comments":true,"path":"2021/12/01/os-简介/","link":"","permalink":"http://wczj.github.io/2021/12/01/os-%E7%AE%80%E4%BB%8B/","excerpt":"","text":"学习内容 操作系统结构 中断及系统调用 内存管理 进程及线程 处理机调度 同步互斥 文件系统 I/O子系统 操作系统是什么？是系统软件，一些程序模块的集合 以尽量 有效，合理 的方式，组织和管理计算机的软硬件资源 合理组织计算机的工作流程，控制程序的执行并并向用户提供各种服务功能 用户能够灵活方便的使用计算机，使整个计算机系统高效率运行 关键词： 有效： 系统资源，资源利用率 CPU， I/O设备 合理： 软硬件资源的管理是否公平合理 方便使用： 用户界面 ， 编程接口 操作系统是资源的管理者：（如何管理？） 跟踪记录资源的使用情况 确定资源分配策略--算法 静态分配策略 动态分配策略 实施资源的分配和回收 提高资源利用率 保护资源的使用 协调多个进程对资源请求的冲突 资源管理角度，操作系统的五大基本功能： 进程/线程管理 （CPU管理） 进程线程状态， 控制，同步互斥，通信，调度， 。。。 存储管理 分配/回收，地址转换，存储保护，内存扩充，。。。 文件管理 文件目录，文件操作，磁盘空间，文件存取控制， 。。。 设备管理 设备驱动，分配回收，缓冲技术， 。。。 用户接口 系统命令，编程接口 操作系统是 各种系统服务的提供者 从用户角度看 操作系统为用户提供了一组功能强大，方便易用的命令或系统调用 典型的服务 进程的创建，执行； 文件目录的操作； I/O设备的使用； 各类统计信息， 。。。 对机器硬件的扩展 操作系统的特征 并发： 处理多个同时活动的能力 1234并发问题： 切换，保护，依赖活动间的同步 单CPU： 宏观上： 程序同时执行 微观上： 任何时刻只有一个程序在真正执行 共享： 123456 操作系统和多个用户程序共同使用计算机中的资源操作系统对资源进行合理分配资源在一个时间段内交替被多个进程使用 互斥共享 （打印机 同时共享 （可重入代码，磁盘文件 虚拟 123456一个物理实体 映射为 若干对应的逻辑实体 -- 分时 或 分空间虚拟是 操作系统 管理 系统资源的重要手段， 提高资源利用率CPU -- 每个进程的 &quot;虚处理器&quot;存储器 -- 每个进程都有独立的虚拟地址空间（代码 + 数据 + 堆栈）显示设备 -- 多窗口 或 虚拟终端 随机 123操作系统必须随时对 以不可预测的次序 发生的事件进行响应并处理 进程运行速度不可预知 难以重新系统在某个时刻的状态 操作系统分类 批处理 12345工作方式 1. 系统操作员收集作业，输入系统，系统形成自动转接的连续作业流 2. 启动操作系统，系统依次执行作业，返回作业结果技术： SPOOLING 利用磁盘做缓冲，将输入，计算，输出 组成独立的任务流，使I/O 和 计算 真正并行 分时操作系统 1234时间片 将CPU的时间划分成片段 操作系统以时间片为单位，轮流为终端用户服务，每次服务一个时间片 利用用户错觉，使用户感受不到计算机在服务他人 实时操作系统 12对外部请求在严格时间范围内做出响应高可靠性 个人计算机操作系统 网络操作系统 123基于计算机网络 功能： 网络管理，通信，安全，资源共享，网络应用 追求目标： 互相通信，资源共享 分布式操作系统 123分布式系统： 或以计算机网络为基础，或以多处理机为基础，分别在不同计算机上分布式操作系统： 统一的，多个计算机协作完成一个任务。 自动实现全系统内的任务分配，调度，均衡工作负载处理能力增强，速度更快，可靠性强，具有透明性 嵌入式操作系统 12嵌入式系统： 在各种设备，装置或系统中， 完成特定功能的软硬件系统嵌入式操作系统： 运行在嵌入式系统环境中，对系统及其所控制的资源进行统一调度，指挥的系统软件","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"简介","slug":"简介","permalink":"http://wczj.github.io/tags/%E7%AE%80%E4%BB%8B/"}]},{"title":"linux-software","slug":"linux-software","date":"2021-11-15T01:40:01.000Z","updated":"2021-11-16T05:40:46.059Z","comments":true,"path":"2021/11/15/linux-software/","link":"","permalink":"http://wczj.github.io/2021/11/15/linux-software/","excerpt":"","text":"linux 环境下各种软件的安装centos 安装 v2ray 服务端 （ 个人VPN搭建）1234yum update -y &amp;&amp; yum install curl -y bash &lt;(curl -s -L https://git.io/v2ray.sh) ## 安装脚本v2ray url ## 生成 vmess链接， 导入客户端 systemctl stop firewalld ## 关闭防火墙 安装zsh 和 oh-my-zsh1234567yum install zsh ## 从gitee上获取安装脚本wget https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh## 编辑 install.sh, 修改以下两行REPO=$&#123;REPO:-mirrors/oh-my-zsh&#125; REMOTE=$&#123;REMOTE:-https://gitee.com/$&#123;REPO&#125;.git&#125;","categories":[],"tags":[]},{"title":"code-review","slug":"code-review","date":"2021-11-04T03:51:53.000Z","updated":"2021-11-04T06:26:08.327Z","comments":true,"path":"2021/11/04/code-review/","link":"","permalink":"http://wczj.github.io/2021/11/04/code-review/","excerpt":"","text":"对旧代码进行review 业务说明 (无业务不开发) 设计思路 (一切实现的基础) 代码层次结构 (逻辑清晰的前提) 代码逻辑说明 (想法的具体实现) 代码好的地方 (开发规范执行完好的地方) 代码坏的地方 (开发规范执行不好的地方) 代码实现经典之处 (牛逼大佬值得学习的地方) 代码实现缺陷遗漏之处 (需要牛逼大佬完善的地方) 对新代码如何进行review参考文章 &lt;&lt;如何在团队中做好Code Review&gt;&gt; , 基本全拷贝，去看这篇文章就可以了 好处 互相学习，彼此成就 你有一个苹果，我有一个苹果，彼此交换一下，我们仍然是各有一个苹果；但你有一种思想，我有一种思想，彼此交换，我们就都有了两种思想，甚至更多。 知识共享，自动互备 在大部分团队，尤其是微服务架构的团队。 通常是一个人员负责多个服务/项目， 如果没有code review， 项目中设计的架构知识，业务知识就只存在于项目过程中产出的说明文档了。 （像我们甚至文档都比较少的）很多设计内容基本只存在于开发人员脑子里。 时间久了，自己都会忘，别人要维护就更难了。 code review 的过程， 至少 Reviewer 必须阅读文档，看代码是否实现相同。 知识的传播性更好，基本不会只有一个人了解某个项目的情况了。 统一风格， 提升质量 代码质量等级： 可以编译通过-&gt;可以正常运行-&gt;可以测试通过-&gt;容易阅读-&gt;容易维护 。 Code Review的代码最起码可以达到易阅读这个级别 要做到易阅读，不是只要有Code Review这个环节就可以了，还要有相关的规范，让大家按照同样的工程风格、编码风格去构建项目和编写代码。 统一风格一方面是让大家无论是维护项目还是阅读代码，不用互相适应各自的编码习惯，另外也是给Reviewer一个Code Review的基本依据。 发现Bug不是Code Review的必需品，而是附属品。至于那些低级的问题/bug交给代码扫描工具就可以了，这不是Code Review的职责。 推动code review落地执行工具 gitlab, 每个项目不同角色， 在合并过程进行 code review 开发规范 工程规范 （工程结构，分层方式，命名等） 命令规范 （接口，类，方法名，变量名） 代码格式 （括号，空格，换行，缩进） 注释规范 （规定必要的注释） 日志规范 （合理的记录必要的日志） 各种推荐和不推荐的代码示例 规范学习网址： Go Code Review Comments(Go官方编程规范翻译) Uber 开源的《Go 语言编码规范 Go 最佳实践: 编写可维护 Go 代码 指定流程规范 确定code review 的实施环节 CodeReview建议是放在代码提交测试前，也就是开发人员完成代码开发及自测后将代码提交到测试分支时进行Code Review。毕竟，如果测试通过后再进行CodeReview，如果需要代码变更，势必会增加测试的工作量，甚至影响项目进度。亦或是顶着项目上线的压力，干脆“以后再说”了 以一般的git 工作流程来说， 就是 功能分支 feature 合并到 开发者分支 develop的时候进行 code review 指定角色行为规范 规范的目的： 控制提交Code Review的代码的粒度 控制单次Code Review的时间 提升Commit/MergeRequest描述的质量，减少沟通成本 通过细粒度高频次的方式尽可能利用工程师碎片化的时间进行Code Review，一定程度上保证Code Review的效率。 分享与统计对code review 的过程及结果进行检验 定期分享 我们期望CodeReview可以让工程师之间互相学习的，那么对于一次Code Review通常只有参与的2-3个工程师有互相学习的机会，那么在这个过程中学到的知识，定期的分享出来，既可以加强知识的流动，又可以检查大家究竟有没有在CodeReview过程中学习到知识，或者有没有认真的进行Code Review 至于分享的内容，可以是开发规范中的范例代码，也可以是规范中的正例代码，也可以是针对某个功能实现的最佳算法/最佳实践，也可以是Code Review过程中的争议代码，也可以是自己踩过的坑。 数据统计 为了在一定程度上保证Code Review的效率，我们在规范里是要求参与的工程师： 1231.Developer控制提交Code Review的粒度，或者控制每个Commit的粒度2.Developer要准确清晰的描述所提交的代码 3.Reviewer&amp;Approver要在规定时间内完成Code Review 这些情况纯粹靠人工是无法检验的，还是需要有一定的数据统计。 12如果用Gerrit，可以查询Gerrit的数据库，里面会有Code Review的信息，如果用GitLab，可以通过WebHook或者restful API获取Code Review信息 我们可以做成报表，来展示Code Review的情况： 123451.每人每周Code Review所消耗的时间2.每人每周被Code Review所消耗的平均时间3.超过规定时间的Code Review情况4.代码提交描述字数过少的情况5.等等（根据自己的需要来） 保证code review质量的关键 工程师 对研发规范的认真学习 资深工程师的认真对待","categories":[],"tags":[]},{"title":"hexo_blog","slug":"hexo-blog","date":"2021-11-04T03:40:17.000Z","updated":"2021-11-04T06:56:31.656Z","comments":true,"path":"2021/11/04/hexo-blog/","link":"","permalink":"http://wczj.github.io/2021/11/04/hexo-blog/","excerpt":"","text":"使用 hexo 搭建博客 使用命令 1234hexo init # 空目录初始化hexo g # 生成hexo s # 本地跑服务hexo d # deploy 部署， 上传到 git 插件安装 1234567## 安装 图片 插件npm install https://github.com/CodeFalling/hexo-asset-image --save## 同时修改配置： post_asset_folder: true ## git部署插件安装， 不然会报git的错误npm install hexo-deployer-git --save 123git page 域名保持不懂在 source 下创建 CNAME 文件， 放入 域名","categories":[],"tags":[]}],"categories":[{"name":"网络协议","slug":"网络协议","permalink":"http://wczj.github.io/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"IM即时通讯","slug":"IM即时通讯","permalink":"http://wczj.github.io/categories/IM%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/"},{"name":"linux","slug":"linux","permalink":"http://wczj.github.io/categories/linux/"},{"name":"设计模式","slug":"设计模式","permalink":"http://wczj.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"http://wczj.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"即时通讯","slug":"即时通讯","permalink":"http://wczj.github.io/tags/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/"},{"name":"linux","slug":"linux","permalink":"http://wczj.github.io/tags/linux/"},{"name":"设计模式","slug":"设计模式","permalink":"http://wczj.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"操作系统","slug":"操作系统","permalink":"http://wczj.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"同步互斥","slug":"同步互斥","permalink":"http://wczj.github.io/tags/%E5%90%8C%E6%AD%A5%E4%BA%92%E6%96%A5/"},{"name":"处理器调度","slug":"处理器调度","permalink":"http://wczj.github.io/tags/%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6/"},{"name":"进程与线程","slug":"进程与线程","permalink":"http://wczj.github.io/tags/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"},{"name":"中断异常","slug":"中断异常","permalink":"http://wczj.github.io/tags/%E4%B8%AD%E6%96%AD%E5%BC%82%E5%B8%B8/"},{"name":"简介","slug":"简介","permalink":"http://wczj.github.io/tags/%E7%AE%80%E4%BB%8B/"}]}